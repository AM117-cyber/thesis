{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5f4806d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fireworks-ai\n",
      "  Obtaining dependency information for fireworks-ai from https://files.pythonhosted.org/packages/7a/a1/167bcc97387dd2b1c3e27dc141c6388ce2b194b28a429c4a3eb34aa15b3a/fireworks_ai-0.17.16-py3-none-any.whl.metadata\n",
      "  Downloading fireworks_ai-0.17.16-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: python-dotenv in c:\\python312\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: httpx in c:\\python312\\lib\\site-packages (from fireworks-ai) (0.27.0)\n",
      "Collecting httpx-ws (from fireworks-ai)\n",
      "  Obtaining dependency information for httpx-ws from https://files.pythonhosted.org/packages/03/3d/2113a5c7af9a13663fa026882d0302ed4142960388536f885dacd6be7038/httpx_ws-0.7.2-py3-none-any.whl.metadata\n",
      "  Downloading httpx_ws-0.7.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting httpx-sse (from fireworks-ai)\n",
      "  Obtaining dependency information for httpx-sse from https://files.pythonhosted.org/packages/e1/9b/a181f281f65d776426002f330c31849b86b31fc9d848db62e16f03ff739f/httpx_sse-0.4.0-py3-none-any.whl.metadata\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: pydantic in c:\\python312\\lib\\site-packages (from fireworks-ai) (2.9.2)\n",
      "Requirement already satisfied: Pillow in c:\\python312\\lib\\site-packages (from fireworks-ai) (10.3.0)\n",
      "Requirement already satisfied: openai in c:\\python312\\lib\\site-packages (from fireworks-ai) (1.51.0)\n",
      "Requirement already satisfied: typing_extensions in c:\\python312\\lib\\site-packages (from fireworks-ai) (4.11.0)\n",
      "Collecting mmh3>=4.1.0 (from fireworks-ai)\n",
      "  Obtaining dependency information for mmh3>=4.1.0 from https://files.pythonhosted.org/packages/12/dd/7cbc30153b73f08eeac43804c1dbc770538a01979b4094edbe1a4b8eb551/mmh3-5.1.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading mmh3-5.1.0-cp312-cp312-win_amd64.whl.metadata (16 kB)\n",
      "Collecting betterproto-fw[compiler]>=2.0.3 (from fireworks-ai)\n",
      "  Obtaining dependency information for betterproto-fw[compiler]>=2.0.3 from https://files.pythonhosted.org/packages/0c/85/fdd477aa981bf80ff610bc256d3c5b079a4294cab74ff6e13cf832bbdaa1/betterproto_fw-2.0.3-py3-none-any.whl.metadata\n",
      "  Downloading betterproto_fw-2.0.3-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting asyncstdlib-fw>=3.13.2 (from fireworks-ai)\n",
      "  Obtaining dependency information for asyncstdlib-fw>=3.13.2 from https://files.pythonhosted.org/packages/bc/6e/3b97da4a8b7bf655f3bb6e55a8bd46b840b5bd14606483d3d2b7e60dbde2/asyncstdlib_fw-3.13.2-py3-none-any.whl.metadata\n",
      "  Downloading asyncstdlib_fw-3.13.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting grpcio>=1.71.0 (from fireworks-ai)\n",
      "  Obtaining dependency information for grpcio>=1.71.0 from https://files.pythonhosted.org/packages/3e/e0/7732afef82ac92a3eaf635546f077ec96e59fe7b7b6729d6607589396cda/grpcio-1.72.1-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading grpcio-1.72.1-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting protobuf==5.29.4 (from fireworks-ai)\n",
      "  Obtaining dependency information for protobuf==5.29.4 from https://files.pythonhosted.org/packages/79/fc/2474b59570daa818de6124c0a15741ee3e5d6302e9d6ce0bdfd12e98119f/protobuf-5.29.4-cp310-abi3-win_amd64.whl.metadata\n",
      "  Downloading protobuf-5.29.4-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting rich>=14.0.0 (from fireworks-ai)\n",
      "  Obtaining dependency information for rich>=14.0.0 from https://files.pythonhosted.org/packages/0d/9b/63f4c7ebc259242c89b3acafdb37b41d1185c07ff0011164674e9076b491/rich-14.0.0-py3-none-any.whl.metadata\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting grpclib<0.5.0,>=0.4.1 (from betterproto-fw[compiler]>=2.0.3->fireworks-ai)\n",
      "  Obtaining dependency information for grpclib<0.5.0,>=0.4.1 from https://files.pythonhosted.org/packages/03/8b/ad381ec1b8195fa4a9a693cb8087e031b99530c0d6b8ad036dcb99e144c4/grpclib-0.4.8-py3-none-any.whl.metadata\n",
      "  Downloading grpclib-0.4.8-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in c:\\python312\\lib\\site-packages (from betterproto-fw[compiler]>=2.0.3->fireworks-ai) (2.8.2)\n",
      "Collecting ruff~=0.9.1 (from betterproto-fw[compiler]>=2.0.3->fireworks-ai)\n",
      "  Obtaining dependency information for ruff~=0.9.1 from https://files.pythonhosted.org/packages/4f/18/fb703603ab108e5c165f52f5b86ee2aa9be43bb781703ec87c66a5f5d604/ruff-0.9.10-py3-none-win_amd64.whl.metadata\n",
      "  Downloading ruff-0.9.10-py3-none-win_amd64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in c:\\python312\\lib\\site-packages (from betterproto-fw[compiler]>=2.0.3->fireworks-ai) (3.1.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\python312\\lib\\site-packages (from rich>=14.0.0->fireworks-ai) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\melissa\\appdata\\roaming\\python\\python312\\site-packages (from rich>=14.0.0->fireworks-ai) (2.17.2)\n",
      "Requirement already satisfied: anyio in c:\\python312\\lib\\site-packages (from httpx->fireworks-ai) (4.4.0)\n",
      "Requirement already satisfied: certifi in c:\\python312\\lib\\site-packages (from httpx->fireworks-ai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\python312\\lib\\site-packages (from httpx->fireworks-ai) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\python312\\lib\\site-packages (from httpx->fireworks-ai) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\python312\\lib\\site-packages (from httpx->fireworks-ai) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\python312\\lib\\site-packages (from httpcore==1.*->httpx->fireworks-ai) (0.14.0)\n",
      "Collecting wsproto (from httpx-ws->fireworks-ai)\n",
      "  Obtaining dependency information for wsproto from https://files.pythonhosted.org/packages/78/58/e860788190eba3bcce367f74d29c4675466ce8dddfba85f7827588416f01/wsproto-1.2.0-py3-none-any.whl.metadata\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\python312\\lib\\site-packages (from openai->fireworks-ai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\python312\\lib\\site-packages (from openai->fireworks-ai) (0.5.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\python312\\lib\\site-packages (from openai->fireworks-ai) (4.66.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\python312\\lib\\site-packages (from pydantic->fireworks-ai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\python312\\lib\\site-packages (from pydantic->fireworks-ai) (2.23.4)\n",
      "Collecting h2<5,>=3.1.0 (from grpclib<0.5.0,>=0.4.1->betterproto-fw[compiler]>=2.0.3->fireworks-ai)\n",
      "  Obtaining dependency information for h2<5,>=3.1.0 from https://files.pythonhosted.org/packages/d0/9e/984486f2d0a0bd2b024bf4bc1c62688fcafa9e61991f041fb0e2def4a982/h2-4.2.0-py3-none-any.whl.metadata\n",
      "  Downloading h2-4.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting multidict (from grpclib<0.5.0,>=0.4.1->betterproto-fw[compiler]>=2.0.3->fireworks-ai)\n",
      "  Obtaining dependency information for multidict from https://files.pythonhosted.org/packages/52/ef/40d98bc5f986f61565f9b345f102409534e29da86a6454eb6b7c00225a13/multidict-6.4.4-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading multidict-6.4.4-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python312\\lib\\site-packages (from jinja2>=3.0.3->betterproto-fw[compiler]>=2.0.3->fireworks-ai) (2.1.5)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=14.0.0->fireworks-ai) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\melissa\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil<3.0.0,>=2.8.0->betterproto-fw[compiler]>=2.0.3->fireworks-ai) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\melissa\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai->fireworks-ai) (0.4.6)\n",
      "Collecting hyperframe<7,>=6.1 (from h2<5,>=3.1.0->grpclib<0.5.0,>=0.4.1->betterproto-fw[compiler]>=2.0.3->fireworks-ai)\n",
      "  Obtaining dependency information for hyperframe<7,>=6.1 from https://files.pythonhosted.org/packages/48/30/47d0bf6072f7252e6521f3447ccfa40b421b6824517f82854703d0f5a98b/hyperframe-6.1.0-py3-none-any.whl.metadata\n",
      "  Downloading hyperframe-6.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting hpack<5,>=4.1 (from h2<5,>=3.1.0->grpclib<0.5.0,>=0.4.1->betterproto-fw[compiler]>=2.0.3->fireworks-ai)\n",
      "  Obtaining dependency information for hpack<5,>=4.1 from https://files.pythonhosted.org/packages/07/c6/80c95b1b2b94682a72cbdbfb85b81ae2daffa4291fbfa1b1464502ede10d/hpack-4.1.0-py3-none-any.whl.metadata\n",
      "  Downloading hpack-4.1.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Downloading fireworks_ai-0.17.16-py3-none-any.whl (569 kB)\n",
      "   ---------------------------------------- 0.0/569.2 kB ? eta -:--:--\n",
      "   -- ------------------------------------ 41.0/569.2 kB 991.0 kB/s eta 0:00:01\n",
      "   ------- -------------------------------- 112.6/569.2 kB 1.3 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 225.3/569.2 kB 1.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 286.7/569.2 kB 1.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 553.0/569.2 kB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 569.2/569.2 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading protobuf-5.29.4-cp310-abi3-win_amd64.whl (434 kB)\n",
      "   ---------------------------------------- 0.0/434.5 kB ? eta -:--:--\n",
      "   ----------------------------------- --- 399.4/434.5 kB 12.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 399.4/434.5 kB 12.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 419.8/434.5 kB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 434.5/434.5 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading asyncstdlib_fw-3.13.2-py3-none-any.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.9/44.9 kB ? eta 0:00:00\n",
      "Downloading grpcio-1.72.1-cp312-cp312-win_amd64.whl (4.2 MB)\n",
      "   ---------------------------------------- 0.0/4.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.5/4.2 MB 14.2 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.8/4.2 MB 10.8 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 1.3/4.2 MB 10.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.8/4.2 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 2.1/4.2 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 2.7/4.2 MB 10.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 3.2/4.2 MB 10.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.5/4.2 MB 9.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 4.0/4.2 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.2/4.2 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.2/4.2 MB 9.0 MB/s eta 0:00:00\n",
      "Downloading mmh3-5.1.0-cp312-cp312-win_amd64.whl (41 kB)\n",
      "   ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 41.5/41.5 kB ? eta 0:00:00\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "   ---------------------------------------- 0.0/243.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 243.2/243.2 kB 14.6 MB/s eta 0:00:00\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading httpx_ws-0.7.2-py3-none-any.whl (14 kB)\n",
      "Downloading grpclib-0.4.8-py3-none-any.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 76.3/76.3 kB 4.4 MB/s eta 0:00:00\n",
      "Downloading ruff-0.9.10-py3-none-win_amd64.whl (11.4 MB)\n",
      "   ---------------------------------------- 0.0/11.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.4 MB 16.0 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.9/11.4 MB 11.8 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 1.4/11.4 MB 9.7 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.0/11.4 MB 11.5 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.4/11.4 MB 10.7 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.8/11.4 MB 9.9 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.2/11.4 MB 10.1 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.6/11.4 MB 10.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.1/11.4 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.6/11.4 MB 10.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.1/11.4 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.6/11.4 MB 9.9 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.1/11.4 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.4/11.4 MB 10.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.8/11.4 MB 9.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.8/11.4 MB 9.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.8/11.4 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.2/11.4 MB 9.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.5/11.4 MB 9.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.9/11.4 MB 9.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.3/11.4 MB 9.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.7/11.4 MB 9.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.1/11.4 MB 9.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.4/11.4 MB 9.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.8/11.4 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.1/11.4 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.4/11.4 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.4/11.4 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.4/11.4 MB 8.4 MB/s eta 0:00:00\n",
      "Downloading betterproto_fw-2.0.3-py3-none-any.whl (105 kB)\n",
      "   ---------------------------------------- 0.0/105.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 105.1/105.1 kB 6.3 MB/s eta 0:00:00\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading h2-4.2.0-py3-none-any.whl (60 kB)\n",
      "   ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 61.0/61.0 kB 3.2 MB/s eta 0:00:00\n",
      "Downloading multidict-6.4.4-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Downloading hpack-4.1.0-py3-none-any.whl (34 kB)\n",
      "Downloading hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: wsproto, ruff, protobuf, multidict, mmh3, hyperframe, httpx-sse, hpack, grpcio, asyncstdlib-fw, rich, h2, httpx-ws, grpclib, betterproto-fw, fireworks-ai\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [Errno 13] Permission denied: 'c:\\\\Python312\\\\Scripts\\\\ruff.exe'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "%pip install fireworks-ai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7595700",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfireworks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Fireworks\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Load environment variables from .env file\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\fireworks\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLM\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msupervised_fine_tuning_job\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SupervisedFineTuningJob\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\fireworks\\llm\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLM\n\u001b[0;32m      3\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLM\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\fireworks\\llm\\llm.py:15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgrpc\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ValidationError\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NotGiven, NOT_GIVEN\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_list_fireworks_models_response_cached\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfireworks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merror\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InvalidRequestError, RateLimitError\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\openai\\__init__.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NOT_GIVEN, NoneType, NotGiven, Transport, ProxiesTypes\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m file_from_path\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_client\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Client, OpenAI, Stream, Timeout, Transport, AsyncClient, AsyncOpenAI, AsyncStream, RequestOptions\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __title__, __version__\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\openai\\_client.py:11\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Self, override\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhttpx\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resources, _exceptions\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_qs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Querystring\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     14\u001b[0m     NOT_GIVEN,\n\u001b[0;32m     15\u001b[0m     Omit,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     RequestOptions,\n\u001b[0;32m     21\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\openai\\resources\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbeta\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      4\u001b[0m     Beta,\n\u001b[0;32m      5\u001b[0m     AsyncBeta,\n\u001b[0;32m      6\u001b[0m     BetaWithRawResponse,\n\u001b[0;32m      7\u001b[0m     AsyncBetaWithRawResponse,\n\u001b[0;32m      8\u001b[0m     BetaWithStreamingResponse,\n\u001b[0;32m      9\u001b[0m     AsyncBetaWithStreamingResponse,\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     12\u001b[0m     Chat,\n\u001b[0;32m     13\u001b[0m     AsyncChat,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     AsyncChatWithStreamingResponse,\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     Audio,\n\u001b[0;32m     21\u001b[0m     AsyncAudio,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m     AsyncAudioWithStreamingResponse,\n\u001b[0;32m     26\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\openai\\resources\\beta\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbeta\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      4\u001b[0m     Beta,\n\u001b[0;32m      5\u001b[0m     AsyncBeta,\n\u001b[0;32m      6\u001b[0m     BetaWithRawResponse,\n\u001b[0;32m      7\u001b[0m     AsyncBetaWithRawResponse,\n\u001b[0;32m      8\u001b[0m     BetaWithStreamingResponse,\n\u001b[0;32m      9\u001b[0m     AsyncBetaWithStreamingResponse,\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mthreads\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     12\u001b[0m     Threads,\n\u001b[0;32m     13\u001b[0m     AsyncThreads,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     AsyncThreadsWithStreamingResponse,\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01massistants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     Assistants,\n\u001b[0;32m     21\u001b[0m     AsyncAssistants,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m     AsyncAssistantsWithStreamingResponse,\n\u001b[0;32m     26\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\openai\\resources\\beta\\beta.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mthreads\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      6\u001b[0m     Threads,\n\u001b[0;32m      7\u001b[0m     AsyncThreads,\n\u001b[0;32m      8\u001b[0m     ThreadsWithRawResponse,\n\u001b[0;32m      9\u001b[0m     AsyncThreadsWithRawResponse,\n\u001b[0;32m     10\u001b[0m     ThreadsWithStreamingResponse,\n\u001b[0;32m     11\u001b[0m     AsyncThreadsWithStreamingResponse,\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cached_property\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Chat, AsyncChat\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\openai\\resources\\beta\\threads\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mruns\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      4\u001b[0m     Runs,\n\u001b[0;32m      5\u001b[0m     AsyncRuns,\n\u001b[0;32m      6\u001b[0m     RunsWithRawResponse,\n\u001b[0;32m      7\u001b[0m     AsyncRunsWithRawResponse,\n\u001b[0;32m      8\u001b[0m     RunsWithStreamingResponse,\n\u001b[0;32m      9\u001b[0m     AsyncRunsWithStreamingResponse,\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mthreads\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     12\u001b[0m     Threads,\n\u001b[0;32m     13\u001b[0m     AsyncThreads,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     AsyncThreadsWithStreamingResponse,\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     Messages,\n\u001b[0;32m     21\u001b[0m     AsyncMessages,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m     AsyncMessagesWithStreamingResponse,\n\u001b[0;32m     26\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\openai\\resources\\beta\\threads\\runs\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mruns\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      4\u001b[0m     Runs,\n\u001b[0;32m      5\u001b[0m     AsyncRuns,\n\u001b[0;32m      6\u001b[0m     RunsWithRawResponse,\n\u001b[0;32m      7\u001b[0m     AsyncRunsWithRawResponse,\n\u001b[0;32m      8\u001b[0m     RunsWithStreamingResponse,\n\u001b[0;32m      9\u001b[0m     AsyncRunsWithStreamingResponse,\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msteps\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     12\u001b[0m     Steps,\n\u001b[0;32m     13\u001b[0m     AsyncSteps,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     AsyncStepsWithStreamingResponse,\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     20\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSteps\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsyncSteps\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsyncRunsWithStreamingResponse\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     33\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\openai\\resources\\beta\\threads\\runs\\runs.py:13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhttpx\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _legacy_response\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msteps\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     14\u001b[0m     Steps,\n\u001b[0;32m     15\u001b[0m     AsyncSteps,\n\u001b[0;32m     16\u001b[0m     StepsWithRawResponse,\n\u001b[0;32m     17\u001b[0m     AsyncStepsWithRawResponse,\n\u001b[0;32m     18\u001b[0m     StepsWithStreamingResponse,\n\u001b[0;32m     19\u001b[0m     AsyncStepsWithStreamingResponse,\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NOT_GIVEN, Body, Query, Headers, NotGiven\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     is_given,\n\u001b[0;32m     24\u001b[0m     required_args,\n\u001b[0;32m     25\u001b[0m     maybe_transform,\n\u001b[0;32m     26\u001b[0m     async_maybe_transform,\n\u001b[0;32m     27\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\openai\\resources\\beta\\threads\\runs\\steps.py:21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpagination\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SyncCursorPage, AsyncCursorPage\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base_client\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AsyncPaginator, make_request_options\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbeta\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mthreads\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mruns\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m step_list_params, step_retrieve_params\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbeta\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mthreads\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mruns\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrun_step\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RunStep\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbeta\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mthreads\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mruns\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrun_step_include\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RunStepInclude\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\openai\\types\\beta\\__init__.py:17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mthread_create_params\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ThreadCreateParams \u001b[38;5;28;01mas\u001b[39;00m ThreadCreateParams\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mthread_update_params\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ThreadUpdateParams \u001b[38;5;28;01mas\u001b[39;00m ThreadUpdateParams\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvector_store_deleted\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VectorStoreDeleted \u001b[38;5;28;01mas\u001b[39;00m VectorStoreDeleted\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01massistant_list_params\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AssistantListParams \u001b[38;5;28;01mas\u001b[39;00m AssistantListParams\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01massistant_tool_choice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AssistantToolChoice \u001b[38;5;28;01mas\u001b[39;00m AssistantToolChoice\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1354\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1316\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1256\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1524\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1498\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1597\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:147\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from fireworks.client import Fireworks\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.environ.get(\"FIREWORKS_API_KEY\")\n",
    "API_MODEL = os.environ.get(\"FIREWORKS_MODEL\")\n",
    "fw = Fireworks(api_key=API_KEY)  # Fixed variable name (was api_key)\n",
    "model_id = API_MODEL\n",
    "\n",
    "conceptos = [\n",
    "    \"inflación\",\n",
    "    \"nutrición básica\",\n",
    "    \"cómo llenar un cheque\",\n",
    "    \"ecuaciones diferenciales\",\n",
    "    \"Shakespeare\",\n",
    "    \"libros\",\n",
    "    \"machine learning\",\n",
    "    \"formatos estáticos\",\n",
    "    \"mecánica cuántica\"\n",
    "]\n",
    "\n",
    "prompt = (\n",
    "    \"Dada la siguiente lista de conceptos, responde solo en JSON clasificándolos en conocidos \"\n",
    "    \"y no conocidos por una persona sin estudios universitarios.\\n\\n\" +\n",
    "    \"\\n\".join(f\"- {c}\" for c in conceptos) +\n",
    "    \"\\n\\nResponde estrictamente en el siguiente formato JSON:\\n\\n\" +\n",
    "    '{\\n  \"conocidos\": [...],\\n  \"no_conocidos\": [...]\\n}'\n",
    ")\n",
    "\n",
    "response = fw.chat.completions.create(\n",
    "    model=model_id,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}  # Fixed: Using the prompt you constructed\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Load the Spanish model from spaCy\n",
    "nlp = spacy.load(\"es_core_news_sm\")  # medium model works better than 'sm' for this\n",
    "\n",
    "# Sample full document\n",
    "text = (\n",
    "    \"\"\"Las estrategias automatizadas, por otro lado, no tienen patrones\n",
    "comunes claros , suelen ser un composición de técnicas como: Segmentación de\n",
    "audio, ya sea a través de detección de silencios u otros features como el tono,\n",
    "la energía o sentimientos. Pero aún es difícil obtener resultados fiables  cuando \n",
    "se trata de diferentes acentos, entornos ruidosos y jerga de dominio específico. El potencial mostrado por el aprendizaje\n",
    "profundo propició el estudio de enfoques exitosos para entrenar pasos de modelado que antes eran separados.\"\"\"\n",
    ")\n",
    "\n",
    "# Split text into paragraphs\n",
    "paragraphs = re.split(r\"\\n\\n+\", text)\n",
    "paragraph_starts = []\n",
    "cursor = 0\n",
    "for para in paragraphs:\n",
    "    paragraph_starts.append(cursor)\n",
    "    cursor += len(para) + 2  # account for \\n\\n\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Define a matcher to extract potential concepts (noun phrases and named entities)\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Pattern for noun phrases (a noun possibly preceded by adjectives/determiners and followed by modifiers)\n",
    "pattern = [\n",
    "    {\"POS\": \"DET\", \"OP\": \"?\"},\n",
    "    {\"POS\": \"ADJ\", \"OP\": \"*\"},\n",
    "    {\"POS\": \"NOUN\", \"OP\": \"+\"},\n",
    "    {\"POS\": \"ADP\", \"OP\": \"*\"},\n",
    "    {\"POS\": \"DET\", \"OP\": \"*\"},\n",
    "    {\"POS\": \"ADJ\", \"OP\": \"*\"},\n",
    "    {\"POS\": \"NOUN\", \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"ConceptPattern\", [pattern])\n",
    "\n",
    "# Apply the matcher\n",
    "matches = matcher(doc)\n",
    "\n",
    "def filter_spans(spans):\n",
    "    result = []\n",
    "    for match in spans:\n",
    "        if not any(\n",
    "            (other.start <= match.start and other.end >= match.end)\n",
    "            and (other != match)  # Avoid comparing the same element\n",
    "            for other in spans\n",
    "        ):\n",
    "            result.append(match)\n",
    "    return result\n",
    "\n",
    "# Extract matched phrases, keeping only longest overlapping ones\n",
    "matched_spans = [doc[start:end] for _, start, end in matches]\n",
    "matched_spans = filter_spans(matched_spans)  # keeps only the longest overlapping matches\n",
    "\n",
    "# Build set of unique concepts with positions\n",
    "concepts = set()\n",
    "concept_spans = []\n",
    "for span in matched_spans:\n",
    "    span_text = span.text.strip()\n",
    "    if len(span_text.split()) > 1 and not all(token.pos_ == \"DET\" for token in span):\n",
    "        if span_text not in concepts:\n",
    "            concepts.add(span_text)\n",
    "            concept_spans.append((span_text, span.start_char, span.end_char))\n",
    "\n",
    "# Also add named entities\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ in [\"PER\", \"ORG\", \"LOC\", \"MISC\"] and ent.text.strip() not in concepts:\n",
    "        concepts.add(ent.text.strip())\n",
    "        concept_spans.append((ent.text.strip(), ent.start_char, ent.end_char))\n",
    "\n",
    "# Function to find paragraph index from char position\n",
    "def get_paragraph_index(start_char):\n",
    "    for i, para_start in enumerate(paragraph_starts):\n",
    "        if start_char < para_start:\n",
    "            return max(0, i - 1)\n",
    "    return len(paragraph_starts) - 1\n",
    "\n",
    "# Definition-like keywords\n",
    "definition_patterns = [\n",
    "    r\"\\\\b(se refiere a|es|significa|consiste en|denominamos|se conoce como|se define como)\\\\b\"\n",
    "]\n",
    "conceptos = []\n",
    "for c in concept_spans:\n",
    "    conceptos.append(c[0])\n",
    "\n",
    "prompt = (\n",
    "    \"\"\"Tienes el siguiente texto en español. Tu tarea consiste en:\n",
    "\n",
    "1. Identificar todos los conceptos, ideas o entidades que aparecen en el primer párrafo y que podrían necesitar una definición. Estos suelen ser frases nominales como \"el problema de los acertijos risueños\" o \"los formatos estáticos\".\n",
    "\n",
    "2. Para cada concepto, revisa los párrafos siguientes y e intenta responder a las siguientes preguntas solo con el contenido del texto: qué es <concepto>?, <concepto> está justificado?. Si las puedes responder, indica:\n",
    "\n",
    "   - Respuesta por pregunta.\n",
    "\n",
    "Si un concepto no está definido explícitamente, simplemente indícalo como \"No definido\".\n",
    "\n",
    "### Texto:\n",
    "Las estrategias automatizadas, por otro lado, no tienen patrones\n",
    "comunes claros , suelen ser un composición de técnicas como: Segmentación de\n",
    "audio, ya sea a través de detección de silencios u otros features como el tono,\n",
    "la energía o sentimientos. Pero aún es difícil obtener resultados fiables  cuando \n",
    "se trata de diferentes acentos, entornos ruidosos y jerga de dominio específico. El potencial mostrado por el aprendizaje\n",
    "profundo propició el estudio de enfoques exitosos para entrenar pasos de modelado que antes eran separados.\n",
    "\n",
    "\n",
    "### Formato de respuesta:\n",
    "\n",
    "1. Concepto: [texto]\n",
    "   - Definido: Sí / No\n",
    "   - Párrafo(s): [número(s) o cita(s)]\n",
    "   - Respuesta a preguntas: respuesta 1, respuesta 2\n",
    "    \"\"\"\n",
    ")\n",
    "# response = fw.chat.completions.create(\n",
    "#     model=model_id,\n",
    "#     messages=[\n",
    "#         {\"role\": \"user\", \"content\": prompt}  # Fixed: Using the prompt you constructed\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# print(response.choices[0].message.content.strip())\n",
    "# text = (\n",
    "#     \"\"\"Las estrategias automatizadas, por otro lado, no tienen patrones\n",
    "# comunes claros , suelen ser un composición de técnicas como: Segmentación de\n",
    "# audio, ya sea a través de detección de silencios u otros features como el tono,\n",
    "# la energía o sentimientos. Pero aún es difícil obtener resultados fiables  cuando \n",
    "# se trata de diferentes acentos, entornos ruidosos y jerga de dominio específico. El potencial mostrado por el aprendizaje\n",
    "# profundo propició el estudio de enfoques exitosos para entrenar pasos de modelado que antes eran separados.\"\"\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb902d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Idea: Las estrategias automatizadas no tienen patrones comunes claros.\n",
      "   - Por qué es ambigua: Se refiere a que las estrategias automatizadas no tienen patrones claros, pero no se especifica qué se entiende exactamente por \"patrones claros\" en este contexto.\n",
      "   - Párrafo(s): Se encuentra en el segundo párrafo del texto.\n",
      "\n",
      "2. Idea: Su composición incluye técnicas como la segmentación de audio.\n",
      "   - Por qué es ambigua: No se aclara qué se entiende por \"deteción de silencios\" en la segmentación de audio.\n",
      "   - Párrafo(s): Se encuentra en el segundo párrafo del texto.\n",
      "\n",
      "3. Idea: Es difícil obtener resultados fiables en diferentes acentos y entornos ruidosos.\n",
      "   - Por qué es ambigua: No se aclara qué se entiende exactamente por \"acentos\" y \"entornos ruidosos\".\n",
      "   - Párrafo(s): Se encuentra en el segundo párrafo del texto.\n",
      "\n",
      "4. Idea: El aprendizaje profundo ha propiciado el estudio de enfoques exitosos para entrenar pasos de modelado separados.\n",
      "   - Por qué es ambigua: No se aclara qué se entiende por \"pasos de modelado separados\".\n",
      "   - Párrafo(s): Se encuentra en el tercer párrafo del texto.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Load the Spanish model from spaCy\n",
    "nlp = spacy.load(\"es_core_news_sm\")  # medium model works better than 'sm' for this\n",
    "\n",
    "# Sample full document\n",
    "text = (\n",
    "    \"\"\"Las estrategias automatizadas, por otro lado, no tienen patrones\n",
    "comunes claros , suelen ser un composición de técnicas como: Segmentación de\n",
    "audio, ya sea a través de detección de silencios u otros features como el tono,\n",
    "la energía o sentimientos. Pero aún es difícil obtener resultados fiables  cuando \n",
    "se trata de diferentes acentos, entornos ruidosos y jerga de dominio específico. El potencial mostrado por el aprendizaje\n",
    "profundo propició el estudio de enfoques exitosos para entrenar pasos de modelado que antes eran separados.\"\"\"\n",
    ")\n",
    "\n",
    "# Split text into paragraphs\n",
    "paragraphs = re.split(r\"\\n\\n+\", text)\n",
    "paragraph_starts = []\n",
    "cursor = 0\n",
    "for para in paragraphs:\n",
    "    paragraph_starts.append(cursor)\n",
    "    cursor += len(para) + 2  # account for \\n\\n\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Define a matcher to extract potential concepts (noun phrases and named entities)\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Pattern for noun phrases (a noun possibly preceded by adjectives/determiners and followed by modifiers)\n",
    "pattern = [\n",
    "    {\"POS\": \"DET\", \"OP\": \"?\"},\n",
    "    {\"POS\": \"ADJ\", \"OP\": \"*\"},\n",
    "    {\"POS\": \"NOUN\", \"OP\": \"+\"},\n",
    "    {\"POS\": \"ADP\", \"OP\": \"*\"},\n",
    "    {\"POS\": \"DET\", \"OP\": \"*\"},\n",
    "    {\"POS\": \"ADJ\", \"OP\": \"*\"},\n",
    "    {\"POS\": \"NOUN\", \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"ConceptPattern\", [pattern])\n",
    "\n",
    "# Apply the matcher\n",
    "matches = matcher(doc)\n",
    "\n",
    "def filter_spans(spans):\n",
    "    result = []\n",
    "    for match in spans:\n",
    "        if not any(\n",
    "            (other.start <= match.start and other.end >= match.end)\n",
    "            and (other != match)  # Avoid comparing the same element\n",
    "            for other in spans\n",
    "        ):\n",
    "            result.append(match)\n",
    "    return result\n",
    "\n",
    "# Extract matched phrases, keeping only longest overlapping ones\n",
    "matched_spans = [doc[start:end] for _, start, end in matches]\n",
    "matched_spans = filter_spans(matched_spans)  # keeps only the longest overlapping matches\n",
    "\n",
    "# Build set of unique concepts with positions\n",
    "concepts = set()\n",
    "concept_spans = []\n",
    "for span in matched_spans:\n",
    "    span_text = span.text.strip()\n",
    "    if len(span_text.split()) > 1 and not all(token.pos_ == \"DET\" for token in span):\n",
    "        if span_text not in concepts:\n",
    "            concepts.add(span_text)\n",
    "            concept_spans.append((span_text, span.start_char, span.end_char))\n",
    "\n",
    "# Also add named entities\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ in [\"PER\", \"ORG\", \"LOC\", \"MISC\"] and ent.text.strip() not in concepts:\n",
    "        concepts.add(ent.text.strip())\n",
    "        concept_spans.append((ent.text.strip(), ent.start_char, ent.end_char))\n",
    "\n",
    "# Function to find paragraph index from char position\n",
    "def get_paragraph_index(start_char):\n",
    "    for i, para_start in enumerate(paragraph_starts):\n",
    "        if start_char < para_start:\n",
    "            return max(0, i - 1)\n",
    "    return len(paragraph_starts) - 1\n",
    "\n",
    "# Definition-like keywords\n",
    "definition_patterns = [\n",
    "    r\"\\\\b(se refiere a|es|significa|consiste en|denominamos|se conoce como|se define como)\\\\b\"\n",
    "]\n",
    "conceptos = []\n",
    "for c in concept_spans:\n",
    "    conceptos.append(c[0])\n",
    "\n",
    "prompt = (\n",
    "    \"\"\"Tienes el siguiente capítulo de una tesis en español. Tu tarea consiste en:\n",
    "\n",
    "1. Identificar las ideas que queden ambiguas o los conceptos que haga falta explicar porque dependan del contexto y no se hayan aclarado en los preliminares, por ejemplo, los adverbios de modo en ocasiones dependen del punto de referencia.\n",
    "Para esto ten en cuenta que en los preliminares de esta tesis se explicó claramente que: Las palabras de comadreja se pueden identificar con un modelo sería necesario entrenar un corpus anotado en español, con el cual no se cuenta actualmente.\n",
    "\n",
    "### Texto:\n",
    "En este trabajo se va a señalar palabras de comadreja. Para esto fue necesario usar una lista porque no se cuenta con un corpus para entrenar algún modelo. Las estrategias automatizadas, por otro lado, no tienen patrones\n",
    "comunes claros , suelen ser un composición de técnicas como: Segmentación de\n",
    "audio, ya sea a través de detección de silencios u otros features como el tono,\n",
    "la energía o sentimientos. Pero aún es difícil obtener resultados fiables  cuando \n",
    "se trata de diferentes acentos, entornos ruidosos y jerga de dominio específico. El potencial mostrado por el aprendizaje\n",
    "profundo propició el estudio de enfoques exitosos para entrenar pasos de modelado que antes eran separados.\n",
    "\n",
    "\n",
    "### Formato de respuesta:\n",
    "\n",
    "1. Idea: [texto]\n",
    "   - Por qué es ambigua: respuesta\n",
    "   - Párrafo(s): [número(s) o cita(s)]\n",
    "    \"\"\"\n",
    ")\n",
    "response = fw.chat.completions.create(\n",
    "    model=model_id,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}  # Fixed: Using the prompt you constructed\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(response.choices[0].message.content.strip())\n",
    "text = (\n",
    "    \"\"\"En este trabajo se va a señalar palabras de comadreja. Para esto fue necesario usar una lista porque no se cuenta con un corpus para entrenar algún modelo.Las estrategias automatizadas, por otro lado, no tienen patrones\n",
    "comunes claros , suelen ser un composición de técnicas como: Segmentación de\n",
    "audio, ya sea a través de detección de silencios u otros features como el tono,\n",
    "la energía o sentimientos. Pero aún es difícil obtener resultados fiables  cuando \n",
    "se trata de diferentes acentos, entornos ruidosos y jerga de dominio específico. El potencial mostrado por el aprendizaje\n",
    "profundo propició el estudio de enfoques exitosos para entrenar pasos de modelado que antes eran separados.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d813ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from google.api_core.exceptions import ResourceExhausted\n",
    "from dotenv import load_dotenv\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a0aff8",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3825833894.py, line 238)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[33], line 238\u001b[1;36m\u001b[0m\n\u001b[1;33m    analysis = self._ask_llm(prompt)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import time\n",
    "from pprint import pprint\n",
    "from fireworks.client import Fireworks\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.environ.get(\"FIREWORKS_API_KEY\")\n",
    "API_MODEL = os.environ.get(\"FIREWORKS_MODEL\")\n",
    "fw = Fireworks(api_key=API_KEY)  # Fixed variable name (was api_key)\n",
    "\n",
    "\n",
    "# To use a real LLM, you would install the library, e.g., 'pip install openai'\n",
    "# from openai import OpenAI\n",
    "\n",
    "# --- Configuration ---\n",
    "MAX_PARAGRAPHS_PER_CHUNK = 5\n",
    "WORD_LIMIT = 400\n",
    "MODEL_ID = API_MODEL\n",
    "NUM_ATTEMPTS_PER_CHUNK = 3\n",
    "\n",
    "\n",
    "class AmbiguityAnalyzer:\n",
    "    def __init__(self, llm_client, word_limit=WORD_LIMIT, max_paragraphs=MAX_PARAGRAPHS_PER_CHUNK, num_attempts=NUM_ATTEMPTS_PER_CHUNK):\n",
    "        self.client = llm_client\n",
    "        self.word_limit = word_limit\n",
    "        self.max_paragraphs = max_paragraphs\n",
    "        self.num_attempts = num_attempts\n",
    "        self.sectioning_pattern = re.compile(r'^\\s*\\\\(chapter|section|subsection|subsubsection)\\{([^}]+)\\}')\n",
    "        self.paragraph_pattern = re.compile(r'^\\s*\\\\(chapter|section|subsection|subsubsection)\\b')\n",
    "\n",
    "    # --- Methods for Ambiguity Analysis (Existing Logic) ---\n",
    "\n",
    "    def _get_paragraphs(self, full_text: str, max_words, paragraph_amount) -> list[str]:\n",
    "        lines = full_text.splitlines()\n",
    "        result = []\n",
    "        curr_chunk = 0\n",
    "        index = 0\n",
    "        word_count = 0\n",
    "        paragraph_count = 0\n",
    "        while index < len(lines):\n",
    "            line = lines[index]\n",
    "            # Check for chapter or section commands\n",
    "            match = re.match(r'^\\s*\\\\(chapter|part|(sub)*section)\\*?\\{(.+?)\\}', line)\n",
    "            \n",
    "            if match:\n",
    "                command = match.group(1)  # e.g., \"section\", \"chapter\", etc.\n",
    "                title = match.group(3)\n",
    "                text = f\"{command}: {title}\"\n",
    "                if len(result) <= curr_chunk:\n",
    "                    result.append(f\"{text} \\n\")\n",
    "                else:\n",
    "                    result[curr_chunk] +=f\"{text} \\n\"\n",
    "                word_count += len(text)\n",
    "            elif line.strip():\n",
    "                word_count += len(line.split())\n",
    "                paragraph_count += 1\n",
    "                if len(result) <= curr_chunk:\n",
    "                    result.append(f\"{line} \\n\")\n",
    "                else:\n",
    "                    result[curr_chunk] += f\"{line} \\n\"\n",
    "                if word_count >= max_words or paragraph_count >= paragraph_amount:\n",
    "                    curr_chunk +=1\n",
    "                    word_count = 0\n",
    "                    paragraph_count = 0\n",
    "            index+=1\n",
    "        return result\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "                # return [line.strip() for line in lines if line.strip() and not self.paragraph_pattern.match(line)]\n",
    "\n",
    "    def _parse_llm_ambiguity_response(self, response_text: str) -> list[dict]:\n",
    "        found = []\n",
    "        pattern = re.compile(r\"Idea:\\s*\\[(.*?)\\].*?Por qué es ambigua:\\s*(.*?)(?=\\n\\d+\\.\\s*Idea:|\\Z)\", re.DOTALL | re.MULTILINE)\n",
    "        for match in pattern.finditer(response_text):\n",
    "            found.append({\"ambiguous_sentence\": match.group(1).strip(), \"reason\": match.group(2).strip()})\n",
    "        return found\n",
    "\n",
    "    def _deduplicate_results(self, results: list[dict]) -> list[dict]:\n",
    "        unique, seen = [], set()\n",
    "        for result in results:\n",
    "            if result['ambiguous_sentence'] not in seen:\n",
    "                unique.append(result)\n",
    "                seen.add(result['ambiguous_sentence'])\n",
    "        return unique\n",
    "\n",
    "    def _ask_llm(self, prompt: str) -> str:\n",
    "        \"\"\"General-purpose method to query the LLM.\"\"\"\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(model=MODEL_ID, messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "            time.sleep(5)\n",
    "            return response.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while calling the LLM API: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def analyze_ambiguity(self, latex_text: str) -> list[dict]:\n",
    "        \"\"\"Main method to process the entire document for ambiguities.\"\"\"\n",
    "        print(\"\\n\" + \"=\"*20 + \" 1. AMBIGUITY ANALYSIS \" + \"=\"*20)\n",
    "        paragraphs = self._get_paragraphs(latex_text, self.word_limit, self.max_paragraphs)\n",
    "        \n",
    "        current_idx = 0\n",
    "        responses = []\n",
    "        while current_idx < len(paragraphs):\n",
    "            chunk_text = paragraphs[current_idx]\n",
    "            print(f\"\\n--- Analyzing chunk number {current_idx} of paragraphs: {paragraphs[current_idx][:150]}---\")\n",
    "            prompt = self._create_ambiguity_prompt(chunk_text)\n",
    "            for i in range(self.num_attempts):\n",
    "                llm_response = self._ask_llm(prompt)\n",
    "                if llm_response:\n",
    "                    if len(responses) <= current_idx:\n",
    "                        responses.append(f\"{llm_response} \\n\")\n",
    "                    responses[current_idx] += f\"{llm_response} \\n\"\n",
    "                    i+=1\n",
    "            current_idx +=1\n",
    "\n",
    "        return responses\n",
    "\n",
    "    def _create_ambiguity_prompt(self, text_chunk: str) -> str:\n",
    "        return (\n",
    "            \"Tienes el siguiente capítulo de una tesis en español. Tu tarea consiste en:\\n\"\n",
    "            \"1. Identificar las ideas que queden ambiguas o los conceptos que haga falta explicar porque dependan del contexto,  por ejemplo, los adverbios de modo en ocasiones dependen del punto de referencia.\\n\"\n",
    "            f\"### Texto a analizar:\\n{text_chunk}\\n\\n\"\n",
    "            \"### Formato de respuesta (usa este formato estricto):\\n\"\n",
    "            \"Idea: [frase exacta del texto]\\n\"\n",
    "            \"   - Por qué es ambigua: [explicación]\\n\"\n",
    "            \"Si no hay ideas ambiguas devolver: NO\"\n",
    "        )\n",
    "    \n",
    "    # --- Methods for Structure and Transition Analysis (New Logic) ---\n",
    "\n",
    "    def _extract_headings(self, latex_text: str) -> str:\n",
    "        \"\"\"Extracts and formats chapter/section headings into a readable list.\"\"\"\n",
    "        headings = []\n",
    "        indent_map = {\"chapter\": 0, \"section\": 2, \"subsection\": 4, \"subsubsection\": 6}\n",
    "        for line in latex_text.splitlines():\n",
    "            match = self.sectioning_pattern.match(line)\n",
    "            if match:\n",
    "                level, title = match.groups()\n",
    "                indent = \" \" * indent_map.get(level, 0)\n",
    "                headings.append(f\"{indent}- {level.capitalize()}: {title}\")\n",
    "        return \"\\n\".join(headings)\n",
    "\n",
    "    def analyze_structure(self, latex_text: str) -> str:\n",
    "        \"\"\"Analyzes the logical distribution of topics based on headings.\"\"\"\n",
    "        print(\"\\n\" + \"=\"*20 + \" 2. STRUCTURE ANALYSIS \" + \"=\"*20)\n",
    "        headings_list_str = self._extract_headings(latex_text)\n",
    "        if not headings_list_str:\n",
    "            return \"No section headings found to analyze.\"\n",
    "            \n",
    "        print(\"--- Sending the following structure to LLM for review: ---\")\n",
    "        print(headings_list_str)\n",
    "        \n",
    "        prompt = (\n",
    "            \"Eres un editor académico experto. Analiza el siguiente índice de una tesis. \"\n",
    "            \"¿La distribución de temas es lógica? ¿El flujo de un capítulo/sección al siguiente parece coherente? \"\n",
    "            \"Proporciona un análisis conciso y sugerencias de mejora si es necesario.\\n\\n\"\n",
    "            f\"### Índice del Documento:\\n{headings_list_str}\\n\\n\"\n",
    "            \"### Análisis:\"\n",
    "        )\n",
    "        return self._ask_llm(prompt)\n",
    "\n",
    "    def _parse_document_structure(self, latex_text: str) -> list:\n",
    "        \"\"\"Parses LaTeX text into a hierarchical list of chapters and sections.\"\"\"\n",
    "        lines = latex_text.splitlines()\n",
    "        document_structure = []\n",
    "        current_chapter = None\n",
    "        current_section = None\n",
    "\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            chapter_match = re.match(r'^\\s*\\\\(chapter|part)\\*?\\{', line)\n",
    "            section_match = re.match(r'^\\s*\\\\(sub)*section\\*?\\{', line)\n",
    "\n",
    "            if chapter_match:\n",
    "                if current_chapter:\n",
    "                    document_structure.append(current_chapter)\n",
    "                current_chapter = {\n",
    "                    \"title\": chapter_match.group(1),\n",
    "                    \"intro_paragraph\": None,\n",
    "                    \"sections\": []\n",
    "                }\n",
    "                current_section = None # Reset section when a new chapter starts\n",
    "            elif section_match and current_chapter:\n",
    "                current_section = {\n",
    "                    \"title\": section_match.group(1),\n",
    "                    \"first_paragraph\": None,\n",
    "                    \"last_paragraph\": None,\n",
    "                }\n",
    "                current_chapter[\"sections\"].append(current_section)\n",
    "            elif not self.paragraph_pattern.match(line): # It's a paragraph\n",
    "                if current_chapter and not current_section and not current_chapter[\"intro_paragraph\"]:\n",
    "                    current_chapter[\"intro_paragraph\"] = line\n",
    "                elif current_section:\n",
    "                    if not current_section[\"first_paragraph\"]:\n",
    "                        current_section[\"first_paragraph\"] = line\n",
    "                    current_section[\"last_paragraph\"] = line # Always update to get the last one\n",
    "        \n",
    "        if current_chapter: # Append the last chapter\n",
    "            document_structure.append(current_chapter)\n",
    "            \n",
    "        return document_structure\n",
    "\n",
    "    def analyze_transitions(self, latex_text: str) -> list[dict]:\n",
    "        \"\"\"Analyzes the narrative flow within and between sections for each chapter.\"\"\"\n",
    "        print(\"\\n\" + \"=\"*20 + \" 3. TRANSITION ANALYSIS \" + \"=\"*20)\n",
    "        transitions_text, general_structure = parse_document_structure(latex_text)\n",
    "\n",
    "        \n",
    "        prompt = (f\"\"\"A continuación tienes un conjunto de inicios de capítulo y secciones. El inicio del capítulo tiene la estructura:\n",
    "                   \n",
    "                  y el inicio de una sección tiene la estructura:\n",
    "                  Tu tarea consiste en:\n",
    "            1. Determinar si el párrafo con el que comienza el capítulo sirve como pequeña introducción al tema del capítulo.\n",
    "            2. Por cada sección determinar si el párrafo que la precede y el que la sigue están interconectados y si hay una transición entre ellos. El último párrafo de una sección debería conectar de alguna manera con el primero de la siguiente.\n",
    "            ### Texto a analizar:{transitions_text}\n",
    "            ### Formato de respuesta (usa este formato estricto):\n",
    "            Si es capítulo: Introducción o no. En caso de no explicar cómo se puede mejorar el párrafo.\n",
    "            Si es sección: Hay transición o no. En caso de no explicar cómo se puede mejorar cada párrafo.\"\"\"\n",
    "        )\n",
    "            \n",
    "        analysis = self._ask_llm(prompt)\n",
    "\n",
    "        return analysis\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sample_latex_text = r\"\"\"\n",
    "\\chapter{Capítulo 1: Fundamentos para el diseño de un sistema de escritura con emojis.}\n",
    "\n",
    "Este capítulo presenta los conceptos que permiten abordar el problema del acceso ágil a emojis desde una perspectiva técnica. Se analizan tres ejes fundamentales: el vínculo entre escritura digital y emojis, los principios ergonómicos que optimizan el uso del teclado, y los enfoques semánticos que permiten representar el significado de frases y símbolos en espacios vectoriales.\n",
    "\n",
    "\n",
    "\\section*{Interacción humano-teclado y escritura con emojis}\n",
    "\n",
    "Más del 90\\,\\% de los usuarios de internet utilizan emojis de forma habitual, según el \\textit{Emoji Trend Report 2021} del Unicode Consortium~\\cite{unicode2021emoji}. Su uso mejora la claridad emocional de los mensajes y se ha vuelto esencial en plataformas de mensajería, redes sociales y entornos digitales informales. Por esta razón los emojis se han transformado  en una herramienta expresiva tan significativa como las palabras.\n",
    "\n",
    "A pesar de esta integración masiva en la comunicación escrita, los métodos actuales para insertar emojis siguen siendo lentos e ineficientes. Navegar por menús gráficos, copiar desde sitios web o memorizar códigos Unicode interrumpe la fluidez de la escritura. Estas barreras afectan especialmente a quienes escriben en teclados físicos, donde no existen accesos rápidos integrados.\n",
    "\n",
    "El teclado continúa siendo la herramienta principal para escribir en dispositivos digitales. Su diseño, centrado en el alfabeto, no contempla de forma nativa el uso de emojis, lo que agrava el problema. Frente a esta limitación, se propone una solución que mejore la experiencia de escritura con emojis desde dos enfoques: asignar los emojis más usados a teclas físicas de forma ergonómica, y ofrecer un buscador semántico que sugiera emojis a partir del significado de frases escritas.\n",
    "\n",
    "\\section*{Principios de ergonomía aplicados al teclado}\n",
    "\n",
    "La ergonomía estudia cómo adaptar herramientas y entornos de trabajo a las capacidades físicas del cuerpo humano. Desde el punto de vista de la escritura digital, un diseño ergonómico del teclado busca reducir el esfuerzo físico, evitar tensiones musculares y mejorar la velocidad y precisión al escribir. Estos principios permiten optimizar la distribución de tareas entre los dedos, minimizar desplazamientos innecesarios y facilitar una escritura más cómoda, rápida y sostenida en el tiempo.\n",
    "\n",
    "\n",
    "La escritura prolongada sin considerar criterios ergonómicos puede provocar incomodidad o fatiga muscular, especialmente en usuarios que utilizan el teclado como herramienta principal. \n",
    "\\section*{Técnica clásica de mecanografía}\n",
    "\n",
    "La mecanografía establece una distribución estándar de los dedos sobre el teclado ~\\cite{zappala1993touch}, orientada a optimizar la velocidad, precisión y ergonomía durante la escritura. Cada dedo tiene asignada una posición de reposo natural, desde la cual debe moverse de forma controlada para alcanzar las teclas correspondientes a cada uno. Esta distribución considera tanto la fuerza como la movilidad de cada dedo, buscando minimizar desplazamientos innecesarios y reducir la fatiga muscular \\cite{norman1990}.\n",
    "\n",
    "La organización parte de una \\textit{fila guía o base} , que es aquella donde descansan los dedos cuando las manos están en posición inicial sobre el teclado. Cada dedo se coloca en una tecla específica sobre esta fila, como se muestra en la Figura~\\ref{fig: posicion_reposo}.\n",
    "\n",
    "\n",
    "\\subsection*{Distribución de teclas asignadas a cada dedo}\n",
    "\n",
    "Cada dedo tiene asignado un conjunto específico de teclas distribuidas en las tres filas principales del teclado alfabético: fila superior, fila guía (base) y fila inferior. Esta distribución sigue el principio de que cada dedo se encargue de un bloque vertical de teclas (columna virtual), minimizando el cruce de dedos y maximizando la eficiencia de la escritura. La Figura \\ref{fig: distribución_dedos}  resume esta asignación. \n",
    "\n",
    "Los pulgares descansan sobre la barra espaciadora. A diferencia de los demás dedos, no participan en la pulsación de letras, por lo que no se incluyen en la distribución anterior.\n",
    "\n",
    "Esta técnica busca reducir el esfuerzo físico durante la escritura al asignar teclas cercanas a cada dedo según su movilidad y fuerza. De esta manera, se favorece una mecanografía más rápida~\\cite{zappala1993touch,norman1990}.\n",
    "\n",
    "Este modelo será aplicado en el Capítulo~3 como base para la asignación de emojis, combinando su frecuencia de uso con el costo ergonómico de cada tecla.\n",
    "La interacción ergonómica, aunque clave para agilizar el acceso a los emojis más usados, no resuelve situaciones donde el usuario no sabe exactamente qué emoji insertar. Para estos casos, es necesario incorporar una lógica de búsqueda más inteligente que relacione el contenido semántico del texto con el significado de los emojis.\n",
    "\n",
    "\\subsection*{Recuperación de información basada en significado}\n",
    "\n",
    "La recuperación de información semántica busca encontrar contenidos relevantes no por coincidencia literal de palabras, sino por su similitud conceptual. A diferencia de los sistemas clásicos de búsqueda que operan con cadenas de texto exactas, un enfoque semántico permite interpretar el significado subyacente de las frases y establecer relaciones con elementos relacionados, aunque estos no compartan las mismas palabras \\cite{manning2008}.\n",
    "\n",
    "Este paradigma se aplica para sugerir emojis que estén vinculados al sentido general de una frase escrita por el usuario. Por ejemplo, ante la frase “extraño a mi familia”, el sistema debería ser capaz de sugerir emojis como \\notaparaelautor{Aquí van unos emojis en cuanto descubra como ponerlos.}, incluso si esas palabras no aparecen literalmente en la base de datos.\n",
    "\n",
    "Este tipo de recuperación se basa en representar tanto frases como conceptos (en este caso, emojis) en un espacio vectorial común. En ese espacio, elementos similares ocupan posiciones cercanas, lo que permite calcular la relevancia mediante medidas de distancia o similitud \\cite{jurafsky2023}.\n",
    "\n",
    "El diseño del módulo semántico se apoya en estos principios, que serán detallados en los siguientes epígrafes junto a las técnicas específicas de vectorización utilizadas.\n",
    "\n",
    "\\subsection*{Representación vectorial de frases y emojis}\n",
    "\n",
    "Para realizar una búsqueda semántica eficiente, es necesario transformar tanto las frases escritas por el usuario como los significados asociados a los emojis en una representación matemática comparable. Este proceso se logra mediante la vectorización, que convierte las unidades lingüísticas en vectores dentro de un espacio semántico.\n",
    "\n",
    "Una técnica ampliamente utilizada para ello es la representación mediante modelos de palabras incrustadas (\\textit{word embeddings}), como Word2Vec, GloVe o FastText. Estos modelos aprenden a representar palabras como puntos en un espacio de múltiples dimensiones, de forma que aquellas que aparecen en contextos similares tienden a ubicarse cerca entre sí \\cite{mikolov2013efficient}.\n",
    "\n",
    "Cuando se trabaja con frases completas, se requiere una estrategia de composición semántica. Una opción simple consiste en promediar los vectores de las palabras que componen la frase. Alternativamente, pueden emplearse técnicas más robustas como la Reducción de Dimensionalidad mediante Análisis Semántico Latente (LSA) o métodos de aprendizaje profundo como \\textit{Transformers}, aunque estos últimos suelen requerir mayor capacidad computacional \\cite{deerwester1990}.\n",
    "\n",
    "En el caso de los emojis, también se puede construir una representación vectorial utilizando descripciones léxicas asociadas a cada uno (por ejemplo, las ofrecidas por Emojipedia). Al vectorizar esas descripciones con el mismo modelo que se usa para las frases, se garantiza que ambas entidades —texto y emoji— puedan compararse directamente mediante medidas como la similitud del coseno.\n",
    "\n",
    "Este enfoque permite establecer correspondencias semánticas entre una entrada textual y un conjunto de emojis candidatos, con base en la proximidad geométrica entre sus vectores. Este mecanismo constituye el núcleo del sistema de búsqueda implementado en el Capítulo~3.\n",
    "\n",
    "\\subsection*{Proceso general de búsqueda semántica}\n",
    "\n",
    "El sistema de búsqueda semántica propuesto sigue una secuencia de etapas que permiten transformar una entrada textual en una sugerencia relevante de emojis. A nivel conceptual, este proceso puede dividirse en cuatro fases principales:\n",
    "\n",
    "\n",
    "Entrada de texto: el usuario escribe una frase o palabra desde la cual desea obtener sugerencias de emojis.\n",
    "    \n",
    "Vectorización: el sistema transforma esa entrada en un vector semántico, utilizando un modelo previamente entrenado para representar el significado del texto.\n",
    "    \n",
    "Comparación semántica: se calcula la similitud entre el vector de la entrada y los vectores asociados a los distintos emojis. Estos últimos se obtienen a partir de sus descripciones textuales, procesadas y vectorizadas del mismo modo que la entrada.\n",
    "    \n",
    "Sugerencia de emojis: el sistema selecciona aquellos emojis con mayor similitud semántica, los ordena y los presenta al usuario como resultados.\n",
    "\n",
    "\n",
    "Este mecanismo permite realizar sugerencias incluso cuando no existe coincidencia textual exacta entre lo escrito y la información asociada a los emojis. Así, se mejora la accesibilidad y relevancia de los resultados, especialmente en contextos donde el usuario no recuerda el nombre exacto del emoji deseado.\n",
    "\n",
    "La implementación de estas etapas, junto con la construcción de la base de datos y las decisiones técnicas específicas, se detalla en el Capítulo~3.\n",
    "\"\"\"\n",
    "    # Use the mock client for the demo\n",
    "    fw_llm_client = fw\n",
    "    analyzer = AmbiguityAnalyzer(llm_client=fw_llm_client)\n",
    "\n",
    "    # --- Run all three analyses ---\n",
    "\n",
    "    # # 1. Ambiguity Analysis\n",
    "    # ambiguity_results = analyzer.analyze_ambiguity(sample_latex_text)\n",
    "    # print(\"\\n--- Final Ambiguity Results ---\")\n",
    "    # pprint(ambiguity_results)\n",
    "\n",
    "    # # 2. Structure Analysis\n",
    "    # structure_analysis = analyzer.analyze_structure(sample_latex_text)\n",
    "    # print(\"\\n--- Final Structure Analysis ---\")\n",
    "    # print(structure_analysis)\n",
    "\n",
    "    # # 3. Transition Analysis\n",
    "    # transition_analysis_results = analyzer.analyze_transitions(sample_latex_text)\n",
    "    # print(\"\\n--- Final Transition Analysis Results ---\")\n",
    "    # pprint(transition_analysis_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2304f78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_text_chunks(text, max_words: int, paragraph_amount: int) -> list[str]:\n",
    "    # text va a ser una lista de tuplas (índice de línea en texto original, línea)\n",
    "    # lines = full_text.splitlines()\n",
    "    result = []\n",
    "    curr_chunk = \"\"\n",
    "    word_count = 0\n",
    "    paragraph_count = 0\n",
    "\n",
    "    for line in text:\n",
    "\n",
    "        # Check for LaTeX structural commands\n",
    "        match = re.match(r'^\\s*\\\\(chapter|part|(sub)*section)\\*?\\{(.+?)\\}', line)\n",
    "        if match:\n",
    "            command = match.group(1)\n",
    "            title = match.group(3)\n",
    "            line_text = f\"{command}: {title} \\n\"\n",
    "            word_count += len(title.split())\n",
    "        else:\n",
    "            line_text = line\n",
    "            word_count += len(line.split())\n",
    "            paragraph_count += 1\n",
    "\n",
    "        curr_chunk += line_text + \" \"\n",
    "\n",
    "        if word_count >= max_words or paragraph_count >= paragraph_amount:\n",
    "            result.append(curr_chunk)\n",
    "            # result.append(curr_chunk.strip())\n",
    "            curr_chunk = \"\"\n",
    "            word_count = 0\n",
    "            paragraph_count = 0\n",
    "\n",
    "    # Append any remaining text\n",
    "    if curr_chunk:\n",
    "        result.append(curr_chunk)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df603758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Ambiguity Results ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --- Run all three analyses ---\n",
    "# 1. Ambiguity Analysis\n",
    "ambiguity_results = get_text_chunks(sample_latex_text, 400, 5)\n",
    "print(\"\\n--- Final Ambiguity Results ---\")\n",
    "i=0\n",
    "output = \"\"\n",
    "while i < len(ambiguity_results):\n",
    "    output += \"chunk number \" + f\"{i}\" + ambiguity_results[i] + \"\\n\"\n",
    "    i+=1\n",
    "with open(\"output.tex\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(output)\n",
    "        f.write(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8f93333",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\,'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\,'\n",
      "C:\\Users\\Melissa\\AppData\\Local\\Temp\\ipykernel_9876\\430798970.py:1: SyntaxWarning: invalid escape sequence '\\,'\n",
      "  text_chunk = \"\"\"chapter: Capítulo 1: Fundamentos para el diseño de un sistema de escritura con emojis.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aquí te presento las ideas ambiguas que he identificado en el texto:\n",
      "\n",
      "1. Idea: \"Más del 90\\,\\% de los usuarios de internet utilizan emojis de forma habitual, según el \textit{Emoji Trend Report 2021} del Unicode Consortium~\\cite{unicode2021emoji}.\"\n",
      "   - Por qué es ambigua: No se especifica qué se entiende por \"utilizar emojis de forma habitual\". ¿Se refiere a utilizar emojis en cada mensaje, en la mayoría de los mensajes, o simplemente a que los usuarios conocen y están familiarizados con ellos?\n",
      "\n",
      "2. Idea: \"Su uso mejora la claridad emocional de los mensajes y se ha vuelto esencial en plataformas de mensajería, redes sociales y entornos digitales informales.\"\n",
      "   - Por qué es ambigua: No se define qué se entiende por \"claridad emocional de los mensajes\". ¿Se refiere a la capacidad de expresar sentimientos y emociones de manera efectiva, o a la capacidad de comunicar la intención o el tono de un mensaje de manera clara?\n",
      "\n",
      "3. Idea: \"Navegar por menús gráficos, copiar desde sitios web o memorizar códigos Unicode interrumpe la fluidez de la escritura.\"\n",
      "   - Por qué es ambigua: No se especifica qué se entiende por \"fluidez de la escritura\". ¿Se refiere a la velocidad, la facilidad o la comodidad con la que se escribe, o a la capacidad de escribir sin interrupciones o distracciones?\n",
      "\n",
      "4. Idea: \"El teclado continúa siendo la herramienta principal para escribir en dispositivos digitales. Su diseño, centrado en el alfabeto, no contempla de forma nativa el uso de emojis, lo que agrava el problema.\"\n",
      "   - Por qué es ambigua: No se define qué se entiende por \"diseño centrado en el alfabeto\". ¿Se refiere a un diseño que prioriza la escritura de texto en alfabeto latino, o a un diseño que se enfoca en la escritura de palabras y frases en general?\n",
      "\n",
      "5. Idea: \"Frente a esta limitación, se propone una solución que mejore la experiencia de escritura con emojis desde dos enfoques: asignar los emojis más usados a teclas físicas de forma ergonómica, y ofrecer un buscador semántico que sugiera emojis a partir del significado de frases escritas.\"\n",
      "   - Por qué es ambigua: No se especifica qué se entiende por \"experiencia de escritura con emojis\". ¿Se refiere a la experiencia de escribir mensajes que incluyen emojis, o a la experiencia de escribir en general cuando se utilizan emojis?\n",
      "\n",
      "6. Idea: \"La ergonomía estudia cómo adaptar herramientas y entornos de trabajo a las capacidades físicas del cuerpo humano.\"\n",
      "   - Por qué es ambigua: No se define qué se entiende por \"capacidades físicas del cuerpo humano\". ¿Se refiere a la capacidad física para escribir, a la capacidad física para utilizar un teclado, o a la capacidad física para interactuar con herramientas y entornos en general?\n",
      "\n",
      "7. Idea: \"Un diseño ergonómico del teclado busca reducir el esfuerzo físico, evitar tensiones musculares y mejorar la velocidad y precisión al escribir.\"\n",
      "   - Por qué es ambigua: No se especifica qué se entiende por \"esfuerzo físico\" o \"tensiones musculares\". ¿Se refiere a la fatiga física o a la tensión muscular en los dedos o en la mano, o a la fatiga física o a la tensión muscular en general?\n",
      "\n",
      "8. Idea: \"Estos principios permiten optimizar la distribución de tareas entre los dedos, minimizar desplazamientos innecesarios y facilitar una escritura más cómoda, rápida y sostenida en el tiempo.\"\n",
      "   - Por qué es ambigua: No se especifica qué se entiende por \"distribución de tareas entre los dedos\". ¿Se refiere a la distribución de tareas entre los dedos de la mano al escribir, o a la distribución de tareas en general entre diferentes partes del cuerpo?\n"
     ]
    }
   ],
   "source": [
    "text_chunk = \"\"\"chapter: Capítulo 1: Fundamentos para el diseño de un sistema de escritura con emojis. \n",
    " Este capítulo presenta los conceptos que permiten abordar el problema del acceso ágil a emojis desde una perspectiva técnica. Se analizan tres ejes fundamentales: el vínculo entre escritura digital y emojis, los principios ergonómicos que optimizan el uso del teclado, y los enfoques semánticos que permiten representar el significado de frases y símbolos en espacios vectoriales. section: Interacción humano-teclado y escritura con emojis \n",
    " Más del 90\\,\\% de los usuarios de internet utilizan emojis de forma habitual, según el \\textit{Emoji Trend Report 2021} del Unicode Consortium~\\cite{unicode2021emoji}. Su uso mejora la claridad emocional de los mensajes y se ha vuelto esencial en plataformas de mensajería, redes sociales y entornos digitales informales. Por esta razón los emojis se han transformado  en una herramienta expresiva tan significativa como las palabras. A pesar de esta integración masiva en la comunicación escrita, los métodos actuales para insertar emojis siguen siendo lentos e ineficientes. Navegar por menús gráficos, copiar desde sitios web o memorizar códigos Unicode interrumpe la fluidez de la escritura. Estas barreras afectan especialmente a quienes escriben en teclados físicos, donde no existen accesos rápidos integrados. El teclado continúa siendo la herramienta principal para escribir en dispositivos digitales. Su diseño, centrado en el alfabeto, no contempla de forma nativa el uso de emojis, lo que agrava el problema. Frente a esta limitación, se propone una solución que mejore la experiencia de escritura con emojis desde dos enfoques: asignar los emojis más usados a teclas físicas de forma ergonómica, y ofrecer un buscador semántico que sugiera emojis a partir del significado de frases escritas. section: Principios de ergonomía aplicados al teclado \n",
    " La ergonomía estudia cómo adaptar herramientas y entornos de trabajo a las capacidades físicas del cuerpo humano. Desde el punto de vista de la escritura digital, un diseño ergonómico del teclado busca reducir el esfuerzo físico, evitar tensiones musculares y mejorar la velocidad y precisión al escribir. Estos principios permiten optimizar la distribución de tareas entre los dedos, minimizar desplazamientos innecesarios y facilitar una escritura más cómoda, rápida y sostenida en el tiempo.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"Tienes el siguiente capítulo de una tesis en español. Tu tarea consiste en:\n",
    "            1. Identificar las ideas que queden ambiguas o los conceptos que haga falta explicar porque dependan del contexto,  por ejemplo, los adverbios de modo en ocasiones dependen del punto de referencia.\n",
    "            ### Texto a analizar:{text_chunk}\n",
    "            ### Formato de respuesta (usa este formato estricto):\n",
    "            Idea: [frase exacta del texto]\n",
    "               - Por qué es ambigua: [explicación]\n",
    "            Si no hay ideas ambiguas devolver: NO\"\"\"\n",
    "llm_response = analyzer._ask_llm(prompt)\n",
    "print(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6619ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\Melissa\\AppData\\Local\\Temp\\ipykernel_9876\\3818525153.py:1: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  melissa_text = \"\"\"\n"
     ]
    }
   ],
   "source": [
    "melissa_text = \"\"\"\n",
    "\\chapter{Propuesta}\\label{chapter:proposal}\n",
    "\n",
    "Dado que no se dispone de un corpus en español anotado específicamente con \\textbf{frases de comadreja} —como se explicó en los preliminares—, este programa opta por utilizar una lista previamente compilada de palabras y expresiones que contribuyen a que el texto se perciba como impreciso y evasivo. Para construir dicha lista, se consultaron varios repositorios disponibles en GitHub \\cite{} que se dedicaban a identificar \\textbf{frases de comadreja} mediante listas predefinidas.\n",
    "\n",
    "En los casos en que las listas estaban en inglés, las entradas se tradujeron manualmente. Si, en cambio, estaban en español, se incorporaron directamente a la lista. Además, se recurrió a la colaboración de profesores de la facultad, quienes aportaron ejemplos reales de frases detectadas durante la corrección de tesis académicas.\n",
    "\n",
    "Una vez reunidos todos los términos, se utilizó un script en Python para eliminar duplicados, garantizando que cada elemento aparezca solo una vez en la lista final. Esta lista fue luego revisada manualmente para descartar expresiones que se pueden utilizar sin generar imprecisión en el texto, por lo cual sería incorrecto clasificarlas como comadrejas.\n",
    "\n",
    "\\section{voz pasiva}\n",
    "Además de las frases de comadreja, otro tipo de error que este trabajo detecta es el uso de la \\textbf{voz pasiva}. Para identificar estas construcciones, se implementó un método que aprovecha las capacidades de análisis gramatical que ofrece \\textit{spaCy}. Esta herramienta permite examinar cada palabra del texto y asignarle dos propiedades fundamentales: su \\textit{lema} —es decir, su forma base o canónica, como ``ser'' en lugar de ``es'' o ``fue''— y su \\textit{categoría gramatical}, también conocida como parte del discurso o \\textit{part of speech} (POS), que indica si se trata de un verbo, sustantivo, adjetivo, entre otros. Luego se recorre el texto palabra por palabra, buscando patrones característicos de la voz pasiva en español.\n",
    "\n",
    "Se considera un patrón de voz pasiva a una palabra cuya categoría gramatical es verbo o auxiliar y su lema es ``ser'', seguida de un participio. Sin embargo, \\textit{spaCy} no es perfecto por lo que no identifica todos los participios correctamente. Para compensar esto se comprueba que la palabra a continuación de la forma verbal de ``ser'' termine en ``ado'', ``ido'', ``to'', ``so'', ``cho'' y no sea un adjetivo, porque lo que es válido que a continuación de la forma verbal de ser venga un adjetivo y algunos de ellos terminan igual que los participios, pero en cualquier otro caso se considera que lo que viene es un participio, aunque \\textit{spaCy} no lo reconozca como tal. \n",
    "\n",
    "\\section{3ra persona}\n",
    "Otro aspecto que se analiza en este trabajo es la presencia de \\textbf{expresiones en primera o segunda persona gramatical}. Para su detección, se desarrolló un método que también utiliza \\textit{spaCy}. En este caso se busca señalar tanto los pronombres personales como las formas verbales correspondientes a la primera y segunda persona del español.\n",
    "\n",
    "Para la detección de pronombres personales en primera y segunda persona, se definió una lista explícita que incluye formas como yo, me, tú, nosotros, entre otras. Aunque \\textit{spaCy} cuenta con mecanismos para identificar la persona gramatical de los pronombres, en la práctica puede cometer errores u omisiones al hacerlo. Dado que el conjunto de pronombres personales en español es limitado y bien definido, se optó por no delegar esta tarea a \\textit{spaCy}  y utilizar directamente una lista controlada. Durante el análisis, si alguno de los elementos de esa lista aparece en el texto y ha sido etiquetado como pronombre (es decir, su categoría gramatical es PRON), se registra su posición para poder marcarlo posteriormente.\n",
    "\n",
    "Por otro lado, también se revisa si los verbos del texto —ya sean simples o compuestos— están conjugados en primera o segunda persona. Para ello, se consultan los rasgos morfológicos de cada verbo, en particular el atributo Person, que indica si se trata de una forma correspondiente a la persona 1 o 2.\n",
    "\n",
    "En el caso de los verbos compuestos, si se detecta un verbo auxiliar en primera o segunda persona (por ejemplo, he, has, hemos), el algoritmo examina los tokens siguientes para verificar si están acompañados de un participio como escrito, leído o visto. Si se encuentra esta estructura, se registra toda la expresión como una construcción en primera o segunda persona, por ejemplo: he escrito o has visto.\n",
    "\n",
    "\\section{anglicismos}\n",
    "También se elaboró una lista de anglicismos con el objetivo de detectarlos en el texto. Para su confección, se recopilaron términos a partir de la fuente \\cite{} y mediante consultas a profesores de la facultad, quienes identificaron los anglicismos más frecuentes en trabajos académicos.\n",
    "\n",
    "Para señalar todos estos errores, se comenta el fragmento de texto correspondiente con un comando de \\LaTeX, como se muestra en la siguiente imagen:\n",
    "\n",
    "\n",
    "Las repeticiones innecesarias de palabras dentro de una oración pueden dificultar la lectura, del mismo modo que las oraciones excesivamente largas pueden generar confusión y dificultar la comprensión del mensaje. Para identificar estos aspectos, el sistema permite al usuario definir dos parámetros: la cantidad máxima de palabras a partir de la cual una oración se considera demasiado larga, y el rango (también en número de palabras) dentro del cual una palabra repetida se considera problemática. Adicionalmente, se establece que una palabra se considera repetida si aparece al menos tres veces dentro de un mismo párrafo. Las oraciones largas se señalan mediante un comando específico, mientras que las palabras repetidas se marcan con un mismo color y se les asigna un índice que permite identificar todas las apariciones de una misma palabra dentro del párrafo. A continuación, se presenta un ejemplo ilustrativo que muestra cómo se señalan estos elementos en el texto:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b322bcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Ambiguity Results ---\n"
     ]
    }
   ],
   "source": [
    "ambiguity_results = get_text_chunks(melissa_text, 400, 5)\n",
    "print(\"\\n--- Final Ambiguity Results ---\")\n",
    "i=0\n",
    "output = \"\"\n",
    "while i < len(ambiguity_results):\n",
    "    output += \"chunk number \" + f\"{i}\" + ambiguity_results[i] + \"\\n\"\n",
    "    i+=1\n",
    "with open(\"output_MELISSA.tex\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(output)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85e19713",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\Melissa\\AppData\\Local\\Temp\\ipykernel_9876\\1560139920.py:1: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  text_chunk = \"\"\"Otro aspecto que se analiza en este trabajo es la presencia de \textbf{expresiones en primera o segunda persona gramatical}. Para su detección, se desarrolló un método que también utiliza \textit{spaCy}. En este caso se busca señalar tanto los pronombres personales como las formas verbales correspondientes a la primera y segunda persona del español. Para la detección de pronombres personales en primera y segunda persona, se definió una lista explícita que incluye formas como yo, me, tú, nosotros, entre otras. Aunque \textit{spaCy} cuenta con mecanismos para identificar la persona gramatical de los pronombres, en la práctica puede cometer errores u omisiones al hacerlo. Dado que el conjunto de pronombres personales en español es limitado y bien definido, se optó por no delegar esta tarea a \textit{spaCy}  y utilizar directamente una lista controlada. Durante el análisis, si alguno de los elementos de esa lista aparece en el texto y ha sido etiquetado como pronombre (es decir, su categoría gramatical es PRON), se registra su posición para poder marcarlo posteriormente. Por otro lado, también se revisa si los verbos del texto —ya sean simples o compuestos— están conjugados en primera o segunda persona. Para ello, se consultan los rasgos morfológicos de cada verbo, en particular el atributo Person, que indica si se trata de una forma correspondiente a la persona 1 o 2. En el caso de los verbos compuestos, si se detecta un verbo auxiliar en primera o segunda persona (por ejemplo, he, has, hemos), el algoritmo examina los tokens siguientes para verificar si están acompañados de un participio como escrito, leído o visto. Si se encuentra esta estructura, se registra toda la expresión como una construcción en primera o segunda persona, por ejemplo: he escrito o has visto. También se elaboró una lista de anglicismos con el objetivo de detectarlos en el texto. Para su confección, se recopilaron términos a partir de la fuente \\cite{} y mediante consultas a profesores de la facultad, quienes identificaron los anglicismos más frecuentes en trabajos académicos.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.  Idea: \"Aunque \textit{spaCy} cuenta con mecanismos para identificar la persona gramatical de los pronombres, en la práctica puede cometer errores u omisiones al hacerlo.\"\n",
      "    -   Por qué es ambigua: Esta idea es ambigua porque no se especifica claramente qué se entiende por \"errores u omisiones\". ¿Se refiere a que  spaCy puede identificar incorrectamente la persona gramatical de los pronombres, o que puede omitir pronombres personales en la detección?\n",
      "\n",
      "2.  Idea: \"Por ejemplo: he escrito o has visto.\"\n",
      "    -   Por qué es ambigua: Esta idea es ambigua porque no se especifica claramente qué se entiende por \"estructura\". ¿Se refiere a la estructura gramatical del verbo auxiliar seguido de un participio, o a una estructura sintáctica más amplia?\n",
      "\n",
      "3.  Idea: \"Para su confección, se recopilaron términos a partir de la fuente \\cite{} y mediante consultas a profesores de la facultad, quienes identificaron los anglicismos más frecuentes en trabajos académicos.\"\n",
      "    -   Por qué es ambigua: Esta idea es ambigua porque no se especifica claramente qué se entiende por \"términos\". ¿Se refiere a palabras, frases, expresiones o algo más?\n",
      "\n",
      "4.  Idea: \"Se consultan los rasgos morfológicos de cada verbo, en particular el atributo Person, que indica si se trata de una forma correspondiente a la persona 1 o 2.\"\n",
      "    -   Por qué es ambigua: Esta idea es ambigua porque no se especifica claramente qué se entiende por \"rasgos morfológicos\". ¿Se refiere a características gramaticales como el género, número, persona, tiempo, modo, voz o algo más?\n"
     ]
    }
   ],
   "source": [
    "text_chunk = \"\"\"Otro aspecto que se analiza en este trabajo es la presencia de \textbf{expresiones en primera o segunda persona gramatical}. Para su detección, se desarrolló un método que también utiliza \textit{spaCy}. En este caso se busca señalar tanto los pronombres personales como las formas verbales correspondientes a la primera y segunda persona del español. Para la detección de pronombres personales en primera y segunda persona, se definió una lista explícita que incluye formas como yo, me, tú, nosotros, entre otras. Aunque \textit{spaCy} cuenta con mecanismos para identificar la persona gramatical de los pronombres, en la práctica puede cometer errores u omisiones al hacerlo. Dado que el conjunto de pronombres personales en español es limitado y bien definido, se optó por no delegar esta tarea a \textit{spaCy}  y utilizar directamente una lista controlada. Durante el análisis, si alguno de los elementos de esa lista aparece en el texto y ha sido etiquetado como pronombre (es decir, su categoría gramatical es PRON), se registra su posición para poder marcarlo posteriormente. Por otro lado, también se revisa si los verbos del texto —ya sean simples o compuestos— están conjugados en primera o segunda persona. Para ello, se consultan los rasgos morfológicos de cada verbo, en particular el atributo Person, que indica si se trata de una forma correspondiente a la persona 1 o 2. En el caso de los verbos compuestos, si se detecta un verbo auxiliar en primera o segunda persona (por ejemplo, he, has, hemos), el algoritmo examina los tokens siguientes para verificar si están acompañados de un participio como escrito, leído o visto. Si se encuentra esta estructura, se registra toda la expresión como una construcción en primera o segunda persona, por ejemplo: he escrito o has visto. También se elaboró una lista de anglicismos con el objetivo de detectarlos en el texto. Para su confección, se recopilaron términos a partir de la fuente \\cite{} y mediante consultas a profesores de la facultad, quienes identificaron los anglicismos más frecuentes en trabajos académicos.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"Tienes el siguiente capítulo de una tesis en español. Tu tarea consiste en:\n",
    "            1. Identificar las ideas que queden ambiguas o los conceptos que haga falta explicar porque dependan del contexto,  por ejemplo, los adverbios de modo en ocasiones dependen del punto de referencia. Si la idea está explicada en alguna parte del texto entonces no se considera ambigua.\n",
    "            ### Texto a analizar:{text_chunk}\n",
    "            ### Formato de respuesta (usa este formato estricto):\n",
    "            Si no hay ideas ambiguas devolver: NO\n",
    "            Si hay ideas ambiguas devolver:\n",
    "            Idea: [frase exacta del texto]\n",
    "               - Por qué es ambigua: [explicación]\n",
    "            \"\"\"\n",
    "llm_response = analyzer._ask_llm(prompt)\n",
    "print(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3959e78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idea: \"Aunque \textit{spaCy} cuenta con mecanismos para identificar la persona gramatical de los pronombres, en la práctica puede cometer errores u omisiones al hacerlo.\"\n",
      "Ambigua/No ambigua: Ambigua\n",
      "Por qué: No se especifica claramente qué se entiende por \"errores u omisiones\". ¿Se refiere a que  spaCy puede identificar incorrectamente la persona gramatical de los pronombres, o que puede omitir pronombres personales en la detección?\n",
      "\n",
      "Idea: \"Por ejemplo: he escrito o has visto.\"\n",
      "Ambigua/No ambigua: Ambigua\n",
      "Por qué: No se especifica claramente qué se entiende por \"estructura\". ¿Se refiere a la estructura gramatical del verbo auxiliar seguido de un participio, o a una estructura sintáctica más amplia?\n",
      "\n",
      "Idea: \"Para su confección, se recopilaron términos a partir de la fuente \\cite{} y mediante consultas a profesores de la facultad, quienes identificaron los anglicismos más frecuentes en trabajos académicos.\"\n",
      "Ambigua/No ambigua: Ambigua\n",
      "Por qué: No se especifica claramente qué se entiende por \"términos\". ¿Se refiere a palabras, frases, expresiones o algo más?\n",
      "\n",
      "Idea: \"Se consultan los rasgos morfológicos de cada verbo, en particular el atributo Person, que indica si se trata de una forma correspondiente a la persona 1 o 2.\"\n",
      "Ambigua/No ambigua: Ambigua\n",
      "Por qué: No se especifica claramente qué se entiende por \"rasgos morfológicos\". ¿Se refiere a características gramaticales como el género, número, persona, tiempo, modo, voz o algo más?\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Tienes el siguiente capítulo de una tesis en español y una lista de ideas. Tu tarea consiste en:\n",
    "            1. Identificar si las ideas quedan ambiguas, es decir, que leyendo el capítulo no es posible aclarar las preguntas que te haces al leerlas.\n",
    "            ### Texto a analizar:{text_chunk}\n",
    "            ### Ideas: {llm_response}\n",
    "            ### Formato de respuesta (usa este formato estricto):\n",
    "            Idea: [idea]\n",
    "            Ambigua/No ambigua: [Si/No]\n",
    "            Por qué: []\n",
    "            \"\"\"\n",
    "new_response = analyzer._ask_llm(prompt)\n",
    "print(new_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53525b5",
   "metadata": {},
   "source": [
    "Transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eff8439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== 3. TRANSITION ANALYSIS ====================\n",
      "### Para capítulo:\n",
      "\n",
      "Introducción: Sí\n",
      "\n",
      "### Para secciones:\n",
      "\n",
      "#### Sección voz pasiva:\n",
      "\n",
      "Transición: Sí\n",
      "\n",
      "#### Sección 3ra persona:\n",
      "\n",
      "Transición: Sí\n",
      "\n",
      "#### Sección anglicismos:\n",
      "\n",
      "Transición: Sí\n"
     ]
    }
   ],
   "source": [
    "def remove_empty_lines(text: str) -> str:\n",
    "    lines = text.splitlines()\n",
    "    non_empty_lines = [line for line in lines if line.strip()]\n",
    "    return \"\\n\".join(non_empty_lines)\n",
    "\n",
    "\n",
    "def parse_document_structure(latex_text: str) -> list:\n",
    "    \"\"\"Parses LaTeX text into a hierarchical list of chapters and sections.\"\"\"\n",
    "    latex_text = remove_empty_lines(latex_text)\n",
    "    lines = latex_text.splitlines()\n",
    "    result = \"\"\n",
    "    general_structure = []\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i].strip()\n",
    "\n",
    "        chapter_match = re.match(r'^\\s*\\\\(chapter|part)\\*?\\{(.+?)\\}', line)\n",
    "        section_match = re.match(r'^\\s*\\\\(sub)*section\\*?\\{(.+?)\\}', line)\n",
    "\n",
    "        if chapter_match:\n",
    "            \n",
    "            title = chapter_match.group(2)  \n",
    "            general_structure.append(f\"Capítulo: {title}\")\n",
    "            result += \"{\"+ f\"Capítulo {title}: \"\n",
    "            i+=1\n",
    "            line = lines[i]\n",
    "            if re.match(r'^\\s*\\\\(chapter|part)\\*?\\{', line) or re.match(r'^\\s*\\\\(sub)*section\\*?\\{', line):\n",
    "                result += \"no text}\\n\"\n",
    "            else:\n",
    "                result += f\"{line}\" + \"}\\n\"\n",
    "                i+=1\n",
    "            \n",
    "        elif section_match:\n",
    "            title = section_match.group(2)\n",
    "            general_structure.append(f\"Sección: {title}\")\n",
    "            result += \"{\"+ f\"Sección {title}: \" \"Párrafo anterior: {\"\n",
    "            prev_line = lines[i-1]\n",
    "            if re.match(r'^\\s*\\\\(chapter|part)\\*?\\{', prev_line) or re.match(r'^\\s*\\\\(sub)*section\\*?\\{', prev_line):\n",
    "                result += \"no text} Párrafo siguiente a sección: {\"\n",
    "            else:\n",
    "                result += f\"{prev_line}\" + \"} Párrafo siguiente a sección: {\"\n",
    "            i+=1\n",
    "            line = lines[i]\n",
    "            if re.match(r'^\\s*\\\\(chapter|part)\\*?\\{', line) or re.match(r'^\\s*\\\\(sub)*section\\*?\\{', line):\n",
    "                result += \"no text}\\n\"\n",
    "            else:\n",
    "                result += f\"{line}\" + \"}\\n\"\n",
    "                i+=1\n",
    "        else:\n",
    "            i+=1\n",
    "        \n",
    "    return result, general_structure\n",
    "\n",
    "\n",
    "def transition_analyzer(llm_client, latex_text: str) -> list[dict]:\n",
    "    \"\"\"Analyzes the narrative flow within and between sections for each chapter.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*20 + \" 3. TRANSITION ANALYSIS \" + \"=\"*20)\n",
    "    transitions_text, general_structure = parse_document_structure(latex_text)\n",
    "\n",
    "    \n",
    "    prompt = (\n",
    "        f\"\"\"A continuación tienes un conjunto de inicios de capítulo y secciones. \n",
    "    El inicio del capítulo tiene la estructura:\n",
    "    {{Capítulo nombre_capítulo: 1er párrafo}}\n",
    "\n",
    "    Y el inicio de una sección tiene la estructura: \n",
    "    Sección nombre_de_sección: Párrafo anterior: {{}} Párrafo siguiente a sección: {{}}\n",
    "\n",
    "    Tu tarea consiste en:\n",
    "\n",
    "    1. Determinar si el párrafo con el que comienza el capítulo sirve como pequeña introducción al tema del capítulo.\n",
    "\n",
    "    2. Por cada sección, determinar si el párrafo que la precede y el que la sigue están interconectados y si hay una transición entre ellos. \n",
    "    Es decir, si hay una transición de una sección a la otra. \n",
    "    El último párrafo de una sección debería conectar de alguna manera con el primero de la siguiente.\n",
    "\n",
    "    ### Texto a analizar:\n",
    "    {transitions_text}\n",
    "\n",
    "    ### Formato de respuesta (usa este formato estricto):\n",
    "\n",
    "    Para capítulo:\n",
    "    Introducción: [Sí/No]\n",
    "    Explicar cómo se puede mejorar el párrafo si la anterior es No: []\n",
    "\n",
    "    Para sección:\n",
    "    Transición: [Sí/No]\n",
    "    Explicar cómo se puede mejorar cada párrafo si la anterior es No: []\n",
    "    \"\"\"\n",
    "    )\n",
    "    answer = llm_client.ask_llm(prompt)\n",
    "    answer = parse_transitions_answer(answer)\n",
    "    return answer, general_structure\n",
    "\n",
    "def logical_order_analyzer(llm_client, gen_structure):\n",
    "    structure = \"\\n\".join(gen_structure)\n",
    "\n",
    "    prompt = (\n",
    "        f\"\"\"A continuación tienes un conjunto de capítulo y secciones que representa el orden en que se trata un tema en un capítulo de una tesis. Si el primer elemento es un capítulo este va a contener el nombre del capítulo a analizar, que siempre viene primero que las secciones y sobre él no debes sugerir cambios.\n",
    "    Tu tarea consiste en:\n",
    "\n",
    "    1. Determinar si el orden propuesto para las secciones dado el nombre del capítulo está bien y en caso contrario sugerir otro orden con la justificación de tu propuesta.\n",
    "    ### Estructura del capítulo:\n",
    "    {structure}\n",
    "\n",
    "    ### Formato de respuesta (usa este formato estricto):\n",
    "\n",
    "    Orden lógico: [Sí/No]\n",
    "    Explicar cómo se puede mejorar el orden si la anterior es No: []\n",
    "\n",
    "    \"\"\"\n",
    "    )\n",
    "        \n",
    "    analysis = llm_client.ask_llm(prompt)\n",
    "    answer = parse_logical_order_analysis(analysis)\n",
    "\n",
    "    return analysis\n",
    "\n",
    "fw_llm_client = fw\n",
    "analyzer = AmbiguityAnalyzer(llm_client=fw_llm_client)  \n",
    "a, general_structure = transition_analyzer(analyzer, melissa_text)\n",
    "\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb9495a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Orden lógico: No\n",
      "### Explicar cómo se puede mejorar el orden si la anterior es No: \n",
      "Parece que el orden no es lógico porque la voz pasiva y la tercera persona no tienen relación directa con el propósito principal del capítulo, que es la propuesta. \n",
      "\n",
      "Una posible mejora sería mover las secciones de la voz pasiva y la tercera persona al final, ya que probablemente se refieran a aspectos específicos de la propuesta y no al propósito principal del capítulo. \n",
      "\n",
      "Aquí te dejo una posible reestructuración:\n",
      "\n",
      "### Estructura del capítulo:\n",
      "['Capítulo: Propuesta', 'Sección: anglicismos', 'Sección: voz pasiva', 'Sección: 3ra persona']\n",
      "\n",
      "En esta reestructuración, la sección de anglicismos es la primera en aparecer porque es probable que se trate de un aspecto general de la propuesta, seguido de la sección de voz pasiva y tercera persona, que es más específica y se refiere a aspectos de la propuesta.\n"
     ]
    }
   ],
   "source": [
    "b = logical_order_analyzer(general_structure)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d06800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ambiguity_response():\n",
    "    \"\"\"Este método devuelve una lista con tuplas de la forma: [Idea ambigua, razón] \"\"\"\n",
    "    # Formato de LLM response\n",
    "    # Idea: \"Aunque \textit{spaCy} cuenta con mecanismos para identificar la persona gramatical de los pronombres, en la práctica puede cometer errores u omisiones al hacerlo.\"\n",
    "    # Ambigua/No ambigua: Ambigua\n",
    "    # Por qué: No se especifica claramente qué se entiende por \"errores u omisiones\". ¿Se refiere a que  spaCy puede identificar incorrectamente la persona gramatical de los pronombres, o que puede omitir pronombres personales en la detección?\n",
    "\n",
    "    # Idea: \"Por ejemplo: he escrito o has visto.\"\n",
    "\n",
    "    return [[\"hola\", \"soy ambigua\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665f3daa",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<string>, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<string>:28\u001b[1;36m\u001b[0m\n\u001b[1;33m    analyzer = AmbiguityAnalyzer(llm_client=fw_llm_client)\u001b[0m\n\u001b[1;37m                                                          ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "from fireworks.client import Fireworks\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.environ.get(\"FIREWORKS_API_KEY\")\n",
    "API_MODEL = os.environ.get(\"FIREWORKS_MODEL\")\n",
    "fw = Fireworks(api_key=API_KEY)  # Fixed variable name (was api_key)\n",
    "model_id = API_MODEL\n",
    "# fw_llm_client = Fireworks_Api(fw, model_id)\n",
    "\n",
    "class Fireworks_Api:\n",
    "    def __init__(self, llm_client, model_id):\n",
    "        self.client = llm_client\n",
    "        self.model_id = model_id\n",
    "\n",
    "    def ask_llm(self, prompt: str) -> str:\n",
    "        \"\"\"General-purpose method to query the LLM.\"\"\"\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(model=self.model_id, messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "            time.sleep(5)\n",
    "            return response.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while calling the LLM API: {e}\")\n",
    "            return \"\"\n",
    "        \n",
    "def check_ambiguity_and_transitions(text_lines_for_LLM, llm_client, line_mapper):\n",
    "    chunks = get_text_chunks(text_lines_for_LLM, 400, 5)\n",
    "    # chunks es un dict en el que las llaves corresponden a la\n",
    "    mark_ambiguity = {}\n",
    "    i = 0\n",
    "    while i < len(chunks):\n",
    "        text_chunk = chunks[i]\n",
    "        first_prompt = f\"\"\"Tienes el siguiente capítulo de una tesis en español. Tu tarea consiste en:\n",
    "                1. Identificar las ideas que queden ambiguas o los conceptos que haga falta explicar porque dependan del contexto,  por ejemplo, los adverbios de modo en ocasiones dependen del punto de referencia. Si la idea está explicada en alguna parte del texto entonces no se considera ambigua.\n",
    "                ### Texto a analizar:{text_chunk}\n",
    "                ### Formato de respuesta (usa este formato estricto):\n",
    "                Si no hay ideas ambiguas devolver: NO\n",
    "                Si hay ideas ambiguas devolver:\n",
    "                Idea: [frase exacta del texto]\n",
    "                - Por qué es ambigua: [explicación]\n",
    "                \"\"\"\n",
    "        llm_response = llm_client.ask_llm(first_prompt)\n",
    "\n",
    "        second_prompt = f\"\"\"Tienes el siguiente capítulo de una tesis en español y una lista de ideas. Tu tarea consiste en:\n",
    "                1. Identificar si las ideas quedan ambiguas, es decir, que leyendo el capítulo no es posible aclarar las preguntas que te haces al leerlas.\n",
    "                ### Texto a analizar:{text_chunk}\n",
    "                ### Ideas: {llm_response}\n",
    "                ### Formato de respuesta (usa este formato estricto):\n",
    "                Idea: [idea]\n",
    "                Ambigua/No ambigua: [Si/No]\n",
    "                Por qué: []\n",
    "                \"\"\"\n",
    "        ambiguous_ideas = parse_ambiguity_response()\n",
    "        \n",
    "        for idea in ambiguous_ideas:\n",
    "            line_idx, sentence_idx = locate_sentence(idea, text_chunk)\n",
    "            og_line_idx = line_mapper[line_idx]\n",
    "            if [og_line_idx, sentence_idx] in mark_ambiguity:\n",
    "                mark_ambiguity[og_line_idx,sentence_idx].append(idea.reason)\n",
    "            else:\n",
    "                mark_ambiguity[og_line_idx,sentence_idx] = idea.reason\n",
    "        i+=1\n",
    "    \n",
    "    #transitions\n",
    "    # vamos a marcar transiciones con nota para el autor\n",
    "    transitions_answer, general_structure = transition_analyzer(llm_client, \"\\n\".join(text_lines_for_LLM)) # devuelve lista de tuplas de la forma: [sección sin transición, sugerencia]\n",
    "    logical_order_answer = logical_order_analyzer(llm_client, general_structure) # devuelve None si no hay sugerencias para el orden, en caso contrario devuelve una nota para el inicio del capítulo\n",
    "    return mark_ambiguity, transitions_answer, logical_order_answer\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073786d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_ambiguous_ideas(text: str) -> list[dict]:\n",
    "    pattern = re.compile(\n",
    "        r\"(?:^\\s*#*\\s*)?Idea:\\s*\\\"(.+?)\\\"\\s*\"                      # optional ### and spaces before Idea:\n",
    "        r\"Ambigua(?:/No ambigua)?:\\s*(Sí|No|Ambigua|No ambigua)\\s*\"\n",
    "        r\"Por qué:\\s*(.+?)(?=\\n(?:\\s*#*\\s*)?Idea:|\\Z)\",            # lookahead for next Idea: possibly prefixed by ### or whitespace\n",
    "        re.DOTALL | re.MULTILINE\n",
    "    )\n",
    "    \n",
    "    matches = pattern.findall(text)\n",
    "    result = []\n",
    "    for idea, status, reason in matches:\n",
    "        if status.strip().lower() == \"ambigua\" or status.strip().lower() == \"si\" or status.strip().lower() == \"sí\":\n",
    "            result.append({\n",
    "                \"idea\": idea.strip(),\n",
    "                \"reason\": reason.strip()\n",
    "            })\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955263d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67db7d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'idea': 'Aunque \\textit{spaCy} cuenta con mecanismos para identificar la persona gramatical de los pronombres, en la práctica puede cometer errores u omisiones al hacerlo.', 'reason': 'No se especifica claramente qué se entiende por \"errores u omisiones\". ¿Se refiere a que  spaCy puede identificar incorrectamente la persona gramatical de los pronombres, o que puede omitir pronombres personales en la detección?'}\n",
      "{'idea': 'su patron característico', 'reason': 'El término \"patrón característico\" no está definido explícitamente en el texto, lo que puede llevar a confusiones sobre qué se entiende por \"patrón característico\" en este contexto. Es posible que se refiera a un patrón lingüístico o gramatical específico, pero no está claro.'}\n"
     ]
    }
   ],
   "source": [
    "text = '''\n",
    "Idea: \"Aunque \textit{spaCy} cuenta con mecanismos para identificar la persona gramatical de los pronombres, en la práctica puede cometer errores u omisiones al hacerlo.\"\n",
    "Ambigua/No ambigua: Ambigua\n",
    "Por qué: No se especifica claramente qué se entiende por \"errores u omisiones\". ¿Se refiere a que  spaCy puede identificar incorrectamente la persona gramatical de los pronombres, o que puede omitir pronombres personales en la detección?\n",
    "\n",
    "Idea: \"su patron característico\"\n",
    "Ambigua: Sí\n",
    "Por qué: El término \"patrón característico\" no está definido explícitamente en el texto, lo que puede llevar a confusiones sobre qué se entiende por \"patrón característico\" en este contexto. Es posible que se refiera a un patrón lingüístico o gramatical específico, pero no está claro.\n",
    "\n",
    "Idea: \"una lista\"\n",
    "Ambigua: Si\n",
    "Por qué: No se especifica qué tipo de lista se refiere, si es una lista de palabras, un catálogo de errores, etc.\n",
    "'''\n",
    "\n",
    "parsed = extract_ambiguous_ideas(text)\n",
    "for item in parsed:\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a40c9201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_sections_without_transition(text: str) -> dict[str, str]:\n",
    "    result = {}\n",
    "\n",
    "    # Match blocks starting with 'Nombre de sección:' and capture the block content\n",
    "    block_pattern = re.compile(\n",
    "        r\"Nombre de sección:\\s*(.+?)\\s*\"\n",
    "        r\"Transición:\\s*(Sí|No)\\s*\"\n",
    "        r\"Sugerencia para incluir transición:\\s*(.+?)(?=\\nNombre de sección:|\\Z)\", \n",
    "        re.DOTALL\n",
    "    )\n",
    "\n",
    "    for name, transition, suggestion in block_pattern.findall(text):\n",
    "        if transition.strip().lower() == \"no\":\n",
    "            result[name.strip()] = suggestion.strip()\n",
    "\n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f6c916f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anglicismos: Se puede mejorar enlazando con el contexto anterior.\n",
      "3ra persona: Se recomienda hacer una referencia más clara a la sección anterior.\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Nombre de sección: voz pasiva\n",
    "Transición: Sí\n",
    "Sugerencia para incluir transición: []\n",
    "\n",
    "Nombre de sección: anglicismos\n",
    "Transición: No\n",
    "Sugerencia para incluir transición: Se puede mejorar enlazando con el contexto anterior.\n",
    "\n",
    "Nombre de sección: 3ra persona\n",
    "Transición: No\n",
    "Sugerencia para incluir transición: Se recomienda hacer una referencia más clara a la sección anterior.\n",
    "\"\"\"\n",
    "\n",
    "result = extract_sections_without_transition(text)\n",
    "for key in result.keys():\n",
    "    print(f\"{key}: {result[key]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e272ba14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_intro_suggestion(text: str) -> str | None:\n",
    "    intro_match = re.search(r'Introducción:\\s*(Sí|No)', text, re.IGNORECASE)\n",
    "    suggestion_match = re.search(r'Sugerencia para mejorar introducción:\\s*(.*)', text, re.IGNORECASE)\n",
    "\n",
    "    if not intro_match or not suggestion_match:\n",
    "        return None  # missing either part\n",
    "\n",
    "    if intro_match.group(1).strip().lower() == \"sí\" or intro_match.group(1).strip().lower() == \"si\":\n",
    "        return None\n",
    "\n",
    "    return suggestion_match.group(1).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7276a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Agregar una introducción contextual.\n"
     ]
    }
   ],
   "source": [
    "text1 = \"\"\"\n",
    "Introducción: Sí\n",
    "Sugerencia para mejorar introducción: Añadir una frase que resuma el contenido del capítulo.\n",
    "\"\"\"\n",
    "\n",
    "text2 = \"\"\"\n",
    "Introducción: No\n",
    "Sugerencia para mejorar introducción: Agregar una introducción contextual.\n",
    "\"\"\"\n",
    "\n",
    "print(get_intro_suggestion(text1))  # ✅ Returns: Añadir una frase que resuma el contenido del capítulo.\n",
    "print(get_intro_suggestion(text2))  # ✅ Returns: None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee227a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_order_suggestion(text: str) -> str | None:\n",
    "    order_match = re.search(r'Orden lógico:\\s*(Sí|No)', text, re.IGNORECASE)\n",
    "\n",
    "    if not order_match:\n",
    "        return None\n",
    "\n",
    "    if order_match.group(1).strip().lower() in [\"sí\", \"si\"]:\n",
    "        return None\n",
    "\n",
    "    # Find the position after the label\n",
    "    label_pattern = re.search(r'Sugerencias de mejora para el orden:\\s*', text, re.IGNORECASE)\n",
    "    \n",
    "    if not label_pattern:\n",
    "        return None\n",
    "\n",
    "    # Get the end position of the match\n",
    "    start_pos = label_pattern.end()\n",
    "\n",
    "    # Return everything after that position\n",
    "    return text[start_pos:].strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53cfcef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Se recomienda organizar los ejemplos de manera progresiva.\n",
      "Esto es un ejemplo:\n",
      "a, b,c\n"
     ]
    }
   ],
   "source": [
    "text1 = \"\"\"\n",
    "Orden lógico: Sí\n",
    "Sugerencias de mejora para el orden: Reordenar los párrafos para empezar con lo más general.\n",
    "\"\"\"\n",
    "\n",
    "text2 = \"\"\"\n",
    "Orden lógico: No\n",
    "Sugerencias de mejora para el orden: Se recomienda organizar los ejemplos de manera progresiva.\n",
    "Esto es un ejemplo:\n",
    "a, b,c\n",
    "\"\"\"\n",
    "\n",
    "print(get_order_suggestion(text1))  # ✅ Returns: Reordenar los párrafos para empezar con lo más general.\n",
    "print(get_order_suggestion(text2))  # ✅ Returns: None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4e5768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load Spanish model (or replace with \"en_core_web_sm\" for English)\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "def find_fragment_location(text: str, fragment: str) -> tuple[int, int] | None:\n",
    "    lines = text.splitlines()\n",
    "\n",
    "    for line_num, line in enumerate(lines):\n",
    "        doc = nlp(line)\n",
    "        for sent_num, sent in enumerate(doc.sents):\n",
    "            if fragment in sent.text:\n",
    "                return (line_num, sent_num) \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a58c50de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0)\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Este es el primer párrafo.\n",
    "Aquí comienza una nueva línea. Este fragmento es relevante.\n",
    "Otra oración que no contiene nada importante.\"\"\"\n",
    "\n",
    "fragment = \"comienza una\"\n",
    "\n",
    "print(find_fragment_location(text, fragment))  # Output: (2, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e936bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_sections_without_transition(text: str) -> dict[str, str]:\n",
    "    result = {}\n",
    "\n",
    "    # Patrón flexible para detectar bloques de sección\n",
    "    block_pattern = re.compile(\n",
    "        r\"(?:\\*\\*.*?\\*\\*\\s*)?\"  # opción para encabezado con negritas (**Sección voz pasiva**)\n",
    "        r\"Nombre de secci[oó]n:\\s*(.+?)\\s*\"\n",
    "        r\"Transici[oó]n:\\s*(Sí|No)\\s*\"\n",
    "        r\"Sugerencia para incluir transici[oó]n:\\s*(.+?)(?=\\n(?:\\*\\*|Nombre de secci[oó]n:|\\Z))\",\n",
    "        re.DOTALL | re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    for name, transition, suggestion in block_pattern.findall(text):\n",
    "        if transition.strip().lower() == \"no\":\n",
    "            result[name.strip()] = suggestion.strip()\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b313f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'palabras de comadreja': 'La seccion de palabras de comadreja deberia explicar cómo estas palabras se encuentran en el texto, para así conectar con la siguiente sección.'}\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Claroo! A continuacion, se presentan las respuestas con el formato solicitado. \n",
    "\n",
    "**Seccion palabras de comadreja: voz pasiva** \n",
    "Nombre de seccion: palabras de comadreja \n",
    "Transicion: No \n",
    "Sugerencia para incluir transicion: La seccion de palabras de comadreja deberia explicar cómo estas palabras se encuentran en el texto, para así conectar con la siguiente sección. \n",
    "\n",
    "**Sección voz pasiva: final** \n",
    "Nombre de sección: voz pasiva \n",
    "Transición: Sí \n",
    "Sugerencia para incluir transición: No hay necesidad de \n",
    "\"\"\"\n",
    "\n",
    "print(extract_sections_without_transition(text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73510b7b",
   "metadata": {},
   "source": [
    "LINE MAPPER\n",
    "0: value: 5\n",
    "1: value: 12\n",
    "2: value: 13\n",
    "3: value: 15\n",
    "4: value: 16\n",
    "5: value: 18\n",
    "6: value: 20\n",
    "count is: 21\n",
    "Not found:Patr�n caracter�stico\" de la voz pasiva\n",
    "Ambigua/No ambigua: Ambigua\n",
    "Por qu�: No se explica qu� se entiende por \"patr�n caracter�stico\" de la voz pasiva, lo que puede llevar a interpretaciones diferentes.\n",
    "\n",
    "Idea: \"Forma verbal del verbo ser\n",
    "Not found:Participio\" (definici�n)\n",
    "Ambigua/No ambigua: Ambigua\n",
    "Por qu�: No se explica qu� se entiende por \"participio\", lo que puede llevar a confusiones sobre la forma verbal en cuesti�n.\n",
    "\n",
    "Idea: \"Identificar todos los errores\n",
    "\n",
    "==================== 3. TRANSITION ANALYSIS ====================\n",
    "### Secci�n 1\n",
    "Nombre de secci�n: palabras de comadreja\n",
    "Transici�n: [No]\n",
    "Sugerencia para incluir transici�n: [Hacer referencia al objetivo de la investigaci�n para conectar con la siguiente secci�n]\n",
    "\n",
    "### Secci�n 2\n",
    "Nombre de secci�n: voz pasiva\n",
    "Transici�n: [S�]\n",
    "Sugerencia para incluir transici�n: [Se refiere a la aplicaci�n del conocimiento de la voz pasiva en el texto, lo que conecta con la secci�n anterior.]\n",
    "\n",
    "### Secci�n 3\n",
    "Nombre de secci�n: final\n",
    "Transici�n: [S�]\n",
    "Sugerencia para incluir transici�n: [La secci�n final resume los resultados de la investigaci�n, lo que conecta con el objetivo de la investigaci�n presentado en la primera secci�n.]\n",
    "\n",
    "{'palabras de comadreja': '[Hacer referencia al objetivo de la investigaci�n para conectar con la siguiente secci�n]'}\n",
    "Missing sentence at index 1 in line 12\n",
    "Modified file saved as: a.tex\n",
    "\n",
    "[Done] exited with code=0 in 33.324 seconds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
